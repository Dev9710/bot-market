"""
GeckoTerminal Scanner V3 - OPTIMISÃ‰ avec enseignements Backtest Phase 2
AmÃ©liorations basÃ©es sur analyse de 3,261 alertes historiques:

NOUVEAUTÃ‰S V3 (Win Rate attendu: 35-50% vs 18.9% actuel):
âœ… Arbitrum DÃ‰SACTIVÃ‰ (4.9% WR catastrophique)
âœ… Base optimisÃ© (seuils augmentÃ©s: $300K liq, $1M vol)
âœ… Filtre vÃ©locitÃ© minimum >5 (Facteur #1: +133% impact)
âœ… Filtre type pump (rejeter LENT: 73% des Ã©checs)
âœ… Filtre Ã¢ge token optimisÃ© (favoriser 2-3 jours: 36.1% WR)
âœ… SystÃ¨me de TIERS (HIGH/MEDIUM/LOW confidence)
âœ… LiquiditÃ© optimale par rÃ©seau
âœ… Watchlist automatique (snowball, RTX, TTD, FIREBALL)
âœ… Scoring dynamique amÃ©liorÃ©

FonctionnalitÃ©s V2 conservÃ©es:
- Multi-pool correlation
- Momentum multi-timeframe
- Traders spike detection
- Buy/Sell pressure evolution
- Alertes ACCELERATION
- RÃ©sistance/Support detection
"""

import sys
import os
import time
import json
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from collections import defaultdict

# SystÃ¨me de sÃ©curitÃ© et tracking
from security_checker import SecurityChecker
from alert_tracker import AlertTracker

# UTF-8 pour emojis Windows
if sys.platform == "win32":
    import io
    if hasattr(sys.stdout, 'buffer') and not isinstance(sys.stdout, io.TextIOWrapper):
        try:
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
        except (ValueError, AttributeError):
            pass

# ============================================
# CONFIGURATION V3 - ImportÃ©e depuis config/
# ============================================

from config.settings import (
    GECKOTERMINAL_API,
    TELEGRAM_BOT_TOKEN,
    TELEGRAM_CHAT_ID,
    NETWORKS,
    NETWORK_NAMES,
    build_network_thresholds,
    DASHBOARD_CONFIG,
    MIN_VELOCITE_PUMP,
    NETWORK_SCORE_FILTERS,
    NETWORK_THRESHOLDS,
    OPTIMAL_VELOCITE_PUMP,
    EXPLOSIVE_VELOCITE_PUMP,
    ALLOWED_PUMP_TYPES,
    REJECTED_PUMP_TYPES,
    MIN_TOKEN_AGE_HOURS,
    EMBRYONIC_AGE_MAX_HOURS,
    OPTIMAL_TOKEN_AGE_MIN_HOURS,
    OPTIMAL_TOKEN_AGE_MAX_HOURS,
    MAX_TOKEN_AGE_HOURS,
    DANGER_ZONE_AGE_MIN,
    DANGER_ZONE_AGE_MAX,
    WATCHLIST_TOKENS,
    VOLUME_LIQUIDITY_RATIO,
    TRADERS_SPIKE_THRESHOLD,
    BUY_RATIO_THRESHOLD,
    BUY_RATIO_CHANGE_THRESHOLD,
    ACCELERATION_THRESHOLD,
    VOLUME_SPIKE_THRESHOLD,
    COOLDOWN_SECONDS,
    MAX_ALERTS_PER_SCAN,
    MIN_PRICE_CHANGE_PERCENT,
    MIN_TIME_HOURS_FOR_REALERT,
    ENABLE_SMART_REALERT,
    ENABLE_ACTIVE_TRACKING,
    ACTIVE_TRACKING_MAX_AGE_HOURS,
    ACTIVE_TRACKING_UPDATE_COOLDOWN_MINUTES,
)

from config.constants import (
    COOLDOWN_REGLE_4,
    COOLDOWN_REGLE_5,
    MAX_LIQUIDITY_THRESHOLD,
)

# ============================================
# UTILITAIRES - ImportÃ©s depuis utils/
# ============================================

from utils.helpers import (
    get_network_display_name,
    log,
    extract_base_token,
    format_price,
)

from utils.telegram import send_telegram

from utils.api_client import (
    get_trending_pools,
    get_new_pools,
    get_pool_by_address,
    parse_pool_data,
)

from data.cache import (
    update_buy_ratio_history,
    get_buy_ratio_change,
)

from core.filters import (
    check_watchlist_token,
    filter_by_velocite,
    filter_by_type_pump,
    filter_by_age,
    filter_by_score_network,
    filter_by_liquidity_range,
    apply_v3_filters,
)

from core.signals import (
    get_price_momentum_from_api,
    find_resistance_simple,
    group_pools_by_token,
    analyze_multi_pool,
    analyze_whale_activity,
    detect_signals,
)

from core.scoring import (
    calculate_base_score,
    calculate_momentum_bonus,
    calculate_confidence_tier,
    calculate_final_score,
    calculate_confidence_score,
)

# ============================================
# CACHE SIMPLIFIÃ‰
# ============================================

# Multi-pool tracking
token_pools = defaultdict(list)  # [base_token] = [pool_data, pool_data, ...]
alert_cooldown = {}

# SystÃ¨me de sÃ©curitÃ© et tracking (initialisÃ©s dans main())
security_checker = None
alert_tracker = None


def check_cooldown(alert_key: str) -> bool:
    """
    VÃ©rifie si alerte en cooldown (LEGACY - utiliser should_send_alert Ã  la place).

    Note: Utilise la variable globale alert_cooldown
    """
    from utils.helpers import check_cooldown as _check_cooldown
    return _check_cooldown(alert_key, alert_cooldown)


def should_send_alert(token_address: str, current_price: float, tracker, regle5_data: Dict = None) -> Tuple[bool, str]:
    """
    DÃ©termine si une alerte doit Ãªtre envoyÃ©e pour un token (FIX BUG #1 - SPAM).

    Logique intelligente:
    - 1Ã¨re alerte: TOUJOURS envoyer
    - Alertes suivantes: SEULEMENT si:
        * TP atteint (TP1/TP2/TP3) OU
        * Prix a variÃ© de Â±5% depuis entry OU
        * 4h se sont Ã©coulÃ©es depuis derniÃ¨re alerte OU
        * Pump parabolique dÃ©tectÃ© (vÃ©locitÃ© >100%/h)

    Returns:
        (should_send: bool, reason: str)
    """
    # VÃ©rifier si c'est la premiÃ¨re alerte pour ce token
    if not tracker.token_already_alerted(token_address):
        return True, "PremiÃ¨re alerte pour ce token"

    # Si systÃ¨me intelligent dÃ©sactivÃ©, toujours envoyer
    if not ENABLE_SMART_REALERT:
        return True, "Smart re-alert dÃ©sactivÃ©"

    # RÃ©cupÃ©rer la derniÃ¨re alerte pour ce token
    previous_alert = tracker.get_last_alert_for_token(token_address)
    if not previous_alert:
        return True, "Pas d'alerte prÃ©cÃ©dente trouvÃ©e"

    # 1. VÃ©rifier si un TP a Ã©tÃ© atteint
    entry_price = previous_alert.get('entry_price', 0)
    tp1_price = previous_alert.get('tp1_price', 0)
    tp2_price = previous_alert.get('tp2_price', 0)
    tp3_price = previous_alert.get('tp3_price', 0)

    # RÃ©cupÃ©rer le prix MAX atteint (pas seulement le prix actuel)
    alert_id = previous_alert.get('id', 0)
    prix_max_atteint = current_price
    if alert_id > 0:
        prix_max_db = tracker.get_highest_price_for_alert(alert_id)
        if prix_max_db:
            prix_max_atteint = max(prix_max_db, current_price)

    # FIX HARMONISATION: TolÃ©rance 0.5% pour cohÃ©rence avec analyser_alerte_suivante()
    TP_TOLERANCE_PERCENT = 0.5

    def tp_reached_with_tolerance(prix: float, tp_target: float) -> bool:
        """VÃ©rifie si TP atteint avec tolÃ©rance pour arrondi."""
        if tp_target <= 0:
            return False
        ecart_percent = ((prix - tp_target) / tp_target) * 100
        return ecart_percent >= -TP_TOLERANCE_PERCENT

    if tp_reached_with_tolerance(prix_max_atteint, tp1_price):
        return True, f"TP atteint (prix max: ${prix_max_atteint:.6f} >= TP1: ${tp1_price:.6f})"

    # 2. VÃ©rifier si le prix a variÃ© de Â±5% depuis entry
    if entry_price > 0:
        price_change_pct = abs((current_price - entry_price) / entry_price * 100)
        if price_change_pct >= MIN_PRICE_CHANGE_PERCENT:
            return True, f"Variation prix significative: {price_change_pct:.1f}% depuis entry"

    # 3. VÃ©rifier le temps Ã©coulÃ© depuis la derniÃ¨re alerte
    created_at_str = previous_alert.get('created_at', '')
    if created_at_str:
        try:
            from datetime import datetime
            created_at = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
            now = datetime.now(created_at.tzinfo) if created_at.tzinfo else datetime.now()
            elapsed = (now - created_at).total_seconds() / 3600  # En heures

            if elapsed >= MIN_TIME_HOURS_FOR_REALERT:
                return True, f"Temps Ã©coulÃ© suffisant: {elapsed:.1f}h"
        except Exception as e:
            log(f"âš ï¸ Erreur parsing date: {e}")

    # 4. VÃ©rifier si pump parabolique (RÃˆGLE 5)
    if regle5_data and regle5_data.get('type_pump') == 'PARABOLIQUE':
        return True, f"Pump PARABOLIQUE dÃ©tectÃ© - Alerte SORTIR urgente"

    # Aucune raison de re-alerter â†’ SPAM PREVENTION
    return False, "Pas de raison de re-alerter"


# ============================================
# SIGNAUX ET ANALYSES - ImportÃ© depuis core/signals
# ============================================
# Les fonctions suivantes sont maintenant importÃ©es de core.signals:
# - get_price_momentum_from_api()
# - find_resistance_simple()
# - group_pools_by_token()
# - analyze_multi_pool()
# - analyze_whale_activity()
# - detect_signals()


# ============================================
# VALIDATION OPPORTUNITÃ‰
# ============================================
def is_valid_opportunity(pool_data: Dict, score: int) -> Tuple[bool, str]:
    """
    VÃ©rifie si pool est une opportunitÃ© valide.
    V3: Applique TOUS les filtres backtest avant validation classique.
    """

    # ===== V3: APPLIQUER FILTRES BACKTEST EN PRIORITÃ‰ =====
    passes_v3, v3_reasons = apply_v3_filters(pool_data)

    # Stocker les raisons V3 dans pool_data pour affichage ultÃ©rieur
    pool_data['v3_filter_reasons'] = v3_reasons

    # Si Ã©chec filtres V3, rejeter immÃ©diatement (sauf watchlist)
    if not passes_v3:
        # ConcatÃ©ner toutes les raisons d'Ã©chec
        failed_reasons = [r for r in v3_reasons if r.startswith('âœ—')]
        if failed_reasons:
            return False, f"[V3 REJECT] {failed_reasons[0].replace('âœ— ', '')}"
        return False, "[V3 REJECT] Filtres backtest non satisfaits"

    # ===== VALIDATION CLASSIQUE (si V3 passÃ©) =====

    # RÃ©cupÃ©rer seuils par rÃ©seau (avec fallback sur default)
    network = pool_data.get("network", "")
    thresholds = NETWORK_THRESHOLDS.get(network, NETWORK_THRESHOLDS["default"])

    min_liq = thresholds["min_liquidity"]
    min_vol = thresholds["min_volume"]
    min_txns = thresholds["min_txns"]

    # Check liquiditÃ© min (dÃ©jÃ  vÃ©rifiÃ© par V3 mais double sÃ©curitÃ©)
    if pool_data["liquidity"] < min_liq:
        return False, f"âŒ LiquiditÃ© trop faible: ${pool_data['liquidity']:,.0f}"

    # Check volume min
    if pool_data["volume_24h"] < min_vol:
        return False, f"âš ï¸ Volume trop faible: ${pool_data['volume_24h']:,.0f}"

    # Check transactions min
    if pool_data["total_txns"] < min_txns:
        return False, f"âš ï¸ Pas assez de txns: {pool_data['total_txns']}"

    # Check age max (dÃ©jÃ  vÃ©rifiÃ© par V3)
    if pool_data["age_hours"] > MAX_TOKEN_AGE_HOURS:
        return False, f"â³ Token trop ancien: {pool_data['age_hours']:.0f}h"

    # Check score minimum (ASSOUPLI pour backtesting: 55 â†’ 50)
    if score < 50:
        return False, f"ğŸ“‰ Score trop faible: {score}/100"

    # Check ratio volume/liquiditÃ©
    ratio = pool_data["volume_24h"] / pool_data["liquidity"] if pool_data["liquidity"] > 0 else 0
    if ratio < VOLUME_LIQUIDITY_RATIO:
        return False, f"ğŸ“‰ Ratio Vol/Liq trop faible: {ratio:.1%}"

    # Check pump & dump potentiel
    buy_sell_ratio = pool_data["buys_24h"] / pool_data["sells_24h"] if pool_data["sells_24h"] > 0 else 999
    if buy_sell_ratio > 5:
        return False, f"ğŸš¨ Trop d'achats vs ventes (pump?): {buy_sell_ratio:.1f}"
    if buy_sell_ratio < 0.2:
        return False, f"ğŸ“‰ Trop de ventes vs achats (dump?): {buy_sell_ratio:.1f}"

    return True, "âœ… OpportunitÃ© valide [V3 APPROVED]"

# ============================================
# Ã‰VALUATION MARCHÃ‰ POUR DÃ‰CISION D'ENTRÃ‰E
# ============================================
def evaluer_conditions_marche(pool_data: Dict, score: int, momentum: Dict,
                              signal_1h: str = None, signal_6h: str = None) -> tuple:
    """
    Ã‰value TOUTES les conditions du marchÃ© pour dÃ©cider si afficher ACTION RECOMMANDÃ‰E.

    Returns:
        (bool, str, list): (should_enter, decision_type, reasons)
        - should_enter: True = afficher Entry/SL/TP, False = afficher analyse de sortie
        - decision_type: "BUY", "WAIT", "EXIT"
        - reasons: Liste des raisons qui justifient la dÃ©cision
    """

    reasons_bullish = []
    reasons_bearish = []
    reasons_neutral = []

    # Extraire les donnÃ©es
    pct_24h = pool_data.get("price_change_24h", 0)
    pct_6h = pool_data.get("price_change_6h", 0)
    pct_1h = pool_data.get("price_change_1h", 0)
    vol_24h = pool_data.get("volume_24h", 0)
    vol_6h = pool_data.get("volume_6h", 0)
    vol_1h = pool_data.get("volume_1h", 0)
    liq = pool_data.get("liquidity", 0)
    buys = pool_data.get("buys_24h", 0)
    sells = pool_data.get("sells_24h", 0)
    buys_1h = pool_data.get("buys_1h", 0)
    sells_1h = pool_data.get("sells_1h", 0)
    age = pool_data.get("age_hours", 0)

    buy_ratio_24h = buys / sells if sells > 0 else 1.0
    buy_ratio_1h = buys_1h / sells_1h if sells_1h > 0 else 1.0

    # ===== 1. ANALYSE DU SCORE =====
    if score >= 80:
        reasons_bullish.append("Score excellent (â‰¥80)")
    elif score >= 70:
        reasons_bullish.append("Score bon (â‰¥70)")
    elif score < 60:
        reasons_bearish.append(f"Score faible ({score})")

    # ===== 2. ANALYSE VOLUME (CRITIQUE) =====
    if vol_24h > 0 and vol_6h > 0 and vol_1h > 0:
        vol_24h_avg = vol_24h / 24
        vol_6h_avg = vol_6h / 6
        ratio_1h_vs_6h = (vol_1h / vol_6h_avg) if vol_6h_avg > 0 else 0
        ratio_6h_vs_24h = (vol_6h_avg / vol_24h_avg) if vol_24h_avg > 0 else 0

        # Volume court terme (1h vs 6h)
        if signal_1h == "FORTE_ACCELERATION":
            reasons_bullish.append("Volume 1h en FORTE accÃ©lÃ©ration")
        elif signal_1h == "ACCELERATION":
            reasons_bullish.append("Volume 1h en accÃ©lÃ©ration")
        elif signal_1h == "RALENTISSEMENT":
            reasons_bearish.append("Volume 1h en RALENTISSEMENT")
        elif signal_1h == "FORT_RALENTISSEMENT":
            reasons_bearish.append("Volume 1h en FORT RALENTISSEMENT")

        # Volume moyen terme (6h vs 24h)
        if signal_6h == "PUMP_EN_COURS":
            reasons_bullish.append("Pump confirmÃ© sur 6h")
        elif signal_6h == "HAUSSE_PROGRESSIVE":
            reasons_bullish.append("Hausse progressive")
        elif signal_6h == "BAISSE_TENDANCIELLE":
            reasons_bearish.append("Baisse tendancielle sur 6h")

        # PATTERNS CRITIQUES
        if signal_1h in ["FORTE_ACCELERATION", "ACCELERATION"] and signal_6h == "PUMP_EN_COURS":
            reasons_bullish.append("ğŸ¯ PATTERN IDÃ‰AL: Pump actif + accÃ©lÃ©ration")
        elif signal_1h in ["RALENTISSEMENT", "FORT_RALENTISSEMENT"] and signal_6h == "PUMP_EN_COURS":
            reasons_bearish.append("âš ï¸ PATTERN SORTIE: Essoufflement dÃ©tectÃ©")
        elif signal_1h in ["RALENTISSEMENT", "FORT_RALENTISSEMENT"]:
            reasons_bearish.append("ğŸ”´ PATTERN Ã‰VITER: Volume en chute")

    # ===== 3. ANALYSE PRIX / MOMENTUM (FIX BUG #4 - Multi-TF Confluence) =====

    # Tendance prix 24h
    if pct_24h >= 20:
        reasons_bullish.append(f"Prix 24h en hausse forte (+{pct_24h:.1f}%)")
    elif pct_24h >= 5:
        reasons_bullish.append(f"Prix 24h en hausse (+{pct_24h:.1f}%)")
    elif pct_24h < -15:
        reasons_bearish.append(f"Prix 24h en baisse ({pct_24h:.1f}%)")

    # NOUVEAU: Multi-Timeframe Confluence (Quick Win #3)
    # DÃ©tecter PULLBACK SAIN sur uptrend (buy the dip)
    if pct_24h >= 5 and -8 < pct_1h < 0:
        # Uptrend 24h + pullback lÃ©ger 1h = BUY THE DIP
        reasons_bullish.append(f"ğŸ“Š PULLBACK SAIN: +{pct_24h:.1f}% 24h | {pct_1h:.1f}% 1h (buy the dip)")
        reasons_bullish.append("âœ… Multi-TF confluence: OpportunitÃ© d'entrÃ©e sur retracement")
    # DÃ©tecter continuation haussiÃ¨re (multi-TF bullish)
    elif pct_24h >= 5 and pct_6h >= 3 and pct_1h >= 2:
        reasons_bullish.append(f"ğŸš€ MULTI-TF BULLISH: Hausse confirmÃ©e sur 24h/6h/1h")
    # Tendance prix court terme (si pas de pullback sain)
    elif pct_1h >= 5:
        reasons_bullish.append(f"Momentum 1h positif (+{pct_1h:.1f}%)")
    elif pct_1h <= -10:
        # Seulement considÃ©rer bearish si vraiment nÃ©gatif (-10%)
        reasons_bearish.append(f"Momentum 1h trÃ¨s nÃ©gatif ({pct_1h:.1f}%)")

    # Analyse de la dÃ©cÃ©lÃ©ration (CRITIQUE pour sortie)
    # MODIFIÃ‰: Seulement si AUCUN pullback sain
    if pct_1h > 0 and pct_6h > 0 and not (pct_24h >= 5 and -8 < pct_1h < 0):
        if pct_1h < pct_6h * 0.5:  # 1h fait moins de 50% du 6h = dÃ©cÃ©lÃ©ration
            reasons_bearish.append("DÃ©cÃ©lÃ©ration: momentum 1h < 50% du 6h")

    # ===== 4. ANALYSE PRESSION ACHAT/VENTE =====
    ratio_change = buy_ratio_1h - buy_ratio_24h

    if ratio_change > 0.15:  # Forte augmentation pression acheteuse
        reasons_bullish.append(f"Pression acheteuse en hausse (+{ratio_change:.1%})")
    elif ratio_change < -0.15:  # Forte augmentation pression vendeuse
        reasons_bearish.append(f"Pression vendeuse en hausse ({ratio_change:.1%})")

    if buy_ratio_1h >= 1.3:
        reasons_bullish.append(f"Acheteurs dominent 1h (ratio {buy_ratio_1h:.2f})")
    elif buy_ratio_1h <= 0.7:
        reasons_bearish.append(f"Vendeurs dominent 1h (ratio {buy_ratio_1h:.2f})")

    # ===== 5. ANALYSE LIQUIDITÃ‰ =====
    if liq < 150000:
        reasons_bearish.append(f"LiquiditÃ© trÃ¨s faible (${liq/1000:.0f}K) - Risque rug Ã©levÃ©")
    elif liq < 200000:
        reasons_neutral.append(f"LiquiditÃ© faible (${liq/1000:.0f}K) - Prudence")
    elif liq >= 500000:
        reasons_bullish.append(f"LiquiditÃ© solide (${liq/1000:.0f}K)")

    # ===== 6. ANALYSE Ã‚GE =====
    if age > 48:
        reasons_neutral.append(f"Token mature ({age:.0f}h) - Exit window peut Ãªtre passÃ©e")
    elif age < 1:
        reasons_neutral.append(f"Token trÃ¨s jeune ({age:.1f}h) - VolatilitÃ© extrÃªme")

    # ===== DÃ‰CISION FINALE (FIX BUG #6 - Score 70+ devrait donner BUY) =====
    score_bullish = len(reasons_bullish)
    score_bearish = len(reasons_bearish)

    # DÃ©tecter patterns critiques
    has_critical_bullish = any("PATTERN IDÃ‰AL" in r or "FORTE accÃ©lÃ©ration" in r or "MULTI-TF BULLISH" in r or "PULLBACK SAIN" in r for r in reasons_bullish)
    has_critical_bearish = any("PATTERN SORTIE" in r or "PATTERN Ã‰VITER" in r or "FORT RALENTISSEMENT" in r for r in reasons_bearish)

    # NOUVELLE LOGIQUE:
    # 1. Score 70+ avec multi-TF confluence â†’ BUY
    # 2. Pattern critique bearish â†’ EXIT
    # 3. Pattern critique bullish + score >= 65 â†’ BUY
    # 4. Score bullish dominant â†’ BUY
    # 5. Sinon â†’ WAIT ou EXIT

    if has_critical_bearish:
        # Bearish critique = SORTIR (mÃªme si score Ã©levÃ©)
        decision = "EXIT"
        should_enter = False
    elif score >= 75 and score_bullish >= 3 and score_bearish <= 1:
        # Score excellent + plusieurs signaux bullish = BUY
        decision = "BUY"
        should_enter = True
    elif score >= 70 and (has_critical_bullish or score_bullish >= 2) and score_bearish <= 1:
        # Score bon + signaux bullish = BUY
        decision = "BUY"
        should_enter = True
    elif has_critical_bullish and score >= 65 and score_bearish <= 2:
        # Pattern idÃ©al/Multi-TF/Pullback sain + score OK = BUY
        decision = "BUY"
        should_enter = True
    elif score_bullish >= 4 and score_bearish <= 1:
        # Beaucoup de signaux bullish = BUY
        decision = "BUY"
        should_enter = True
    elif score_bearish >= 3 or score < 60:
        # Trop bearish ou score faible = EXIT
        decision = "EXIT"
        should_enter = False
    elif score_bullish >= 2 and score_bearish <= 2:
        # MitigÃ© = WAIT
        decision = "WAIT"
        should_enter = False
    else:
        # DÃ©faut = EXIT
        decision = "EXIT"
        should_enter = False

    return should_enter, decision, {
        'bullish': reasons_bullish,
        'bearish': reasons_bearish,
        'neutral': reasons_neutral
    }

# ============================================
# ANALYSE ALERTE SUIVANTE (TP TRACKING)
# ============================================
def analyser_alerte_suivante(previous_alert: Dict, current_price: float, pool_data: Dict,
                             score: int, momentum: Dict, signal_1h: str = None,
                             signal_6h: str = None, tracker=None) -> Dict:
    """
    Analyse une alerte suivante sur un token dÃ©jÃ  alertÃ©.
    VÃ©rifie si les TP ont Ã©tÃ© atteints et dÃ©cide de la stratÃ©gie.

    VERSION SIMPLE+ - 5 RÃˆGLES ESSENTIELLES:
    1. DÃ©tection des TP atteints
    2. VÃ©rification du prix (pas trop Ã©levÃ© pour re-entry)
    3. RÃ©Ã©valuation des conditions actuelles
    4. DÃ©cision: NOUVEAUX_NIVEAUX / SECURISER_HOLD / SORTIR
    5. Analyse vÃ©locitÃ© du pump (protection pump parabolique)

    Args:
        previous_alert: DerniÃ¨re alerte sur ce token (depuis DB)
        current_price: Prix actuel du token
        pool_data: DonnÃ©es actuelles du pool
        score: Score actuel
        momentum: Momentum actuel
        signal_1h: Signal volume 1h vs 6h
        signal_6h: Signal volume 6h vs 24h

    Returns:
        Dict avec:
            - decision: "NOUVEAUX_NIVEAUX" / "SECURISER_HOLD" / "SORTIR"
            - tp_hit: Liste des TP atteints ["TP1", "TP2", "TP3"]
            - tp_gains: Dict avec les gains rÃ©alisÃ©s {"TP1": 5.0, ...}
            - prix_trop_eleve: bool
            - conditions_favorables: bool
            - raisons: Liste des raisons de la dÃ©cision
            - nouveaux_niveaux: Dict (si applicable) avec entry/sl/tp
            - velocite_pump: float (% par heure)
            - type_pump: str (PARABOLIQUE / RAPIDE / NORMAL / LENT)
    """

    # VALIDATION: VÃ©rifier que previous_alert et pool_data sont valides
    if not previous_alert or not isinstance(previous_alert, dict):
        log(f"   âš ï¸ previous_alert invalide: {type(previous_alert)}")
        return {
            'decision': 'ERROR',
            'tp_hit': [],
            'tp_gains': {},
            'prix_trop_eleve': False,
            'conditions_favorables': False,
            'raisons': ["DonnÃ©es d'alerte prÃ©cÃ©dente invalides"],
            'nouveaux_niveaux': {},
            'hausse_depuis_alerte': 0,
            'velocite_pump': 0,
            'type_pump': 'UNKNOWN',
            'temps_ecoule_heures': 0
        }

    if not pool_data or not isinstance(pool_data, dict):
        log(f"   âš ï¸ pool_data invalide dans analyser_alerte_suivante: {type(pool_data)}")
        return {
            'decision': 'ERROR',
            'tp_hit': [],
            'tp_gains': {},
            'prix_trop_eleve': False,
            'conditions_favorables': False,
            'raisons': ["DonnÃ©es de pool invalides"],
            'nouveaux_niveaux': {},
            'hausse_depuis_alerte': 0,
            'velocite_pump': 0,
            'type_pump': 'UNKNOWN',
            'temps_ecoule_heures': 0
        }

    if not momentum or not isinstance(momentum, dict):
        log(f"   âš ï¸ momentum invalide dans analyser_alerte_suivante: {type(momentum)}")
        return {
            'decision': 'ERROR',
            'tp_hit': [],
            'tp_gains': {},
            'prix_trop_eleve': False,
            'conditions_favorables': False,
            'raisons': ["DonnÃ©es de momentum invalides"],
            'nouveaux_niveaux': {},
            'hausse_depuis_alerte': 0,
            'velocite_pump': 0,
            'type_pump': 'UNKNOWN',
            'temps_ecoule_heures': 0
        }

    # RÃˆGLE 1: DÃ©tection des TP atteints
    # IMPORTANT: On vÃ©rifie si les TP ont Ã©tÃ© atteints DANS LE PASSÃ‰ (pas juste le prix actuel)
    tp_hit = []
    tp_gains = {}

    tp1_price = previous_alert.get('tp1_price', 0)
    tp2_price = previous_alert.get('tp2_price', 0)
    tp3_price = previous_alert.get('tp3_price', 0)
    entry_price = previous_alert.get('entry_price', previous_alert.get('price_at_alert', 0))

    # RÃ©cupÃ©rer le prix MAX atteint depuis l'alerte prÃ©cÃ©dente (depuis price_tracking)
    # Si pas de tracking disponible, utiliser le prix actuel comme fallback
    alert_id = previous_alert.get('id', 0)
    prix_max_atteint = current_price  # Fallback par dÃ©faut

    # Si le tracker est disponible, rÃ©cupÃ©rer le VRAI prix MAX depuis la DB
    if tracker is not None and alert_id > 0:
        prix_max_db = tracker.get_highest_price_for_alert(alert_id)
        if prix_max_db is not None:
            # Comparer avec le prix actuel et prendre le max
            prix_max_atteint = max(prix_max_db, current_price)
            # Note: On prend le max car le prix actuel peut Ãªtre > que le dernier tracking

    # FIX HARMONISATION: TolÃ©rance 0.5% pour Ã©viter problÃ¨mes d'arrondi
    # Exemple: TP1=$0.1575, prix=$0.1574 â†’ considÃ©rÃ© comme atteint (Ã©cart 0.06%)
    TP_TOLERANCE_PERCENT = 0.5  # 0.5% de tolÃ©rance

    def tp_reached(prix: float, tp_target: float) -> bool:
        """VÃ©rifie si TP atteint avec tolÃ©rance pour arrondi."""
        if tp_target <= 0:
            return False
        ecart_percent = ((prix - tp_target) / tp_target) * 100
        # TP atteint si prix >= TP - 0.5%
        return ecart_percent >= -TP_TOLERANCE_PERCENT

    # DEBUG: Log pour comprendre dÃ©tection TP
    if alert_id > 0:
        log(f"   ğŸ” DEBUG TP: prix_max={prix_max_atteint:.8f}, tp1={tp1_price:.8f}, tp2={tp2_price:.8f}, tp3={tp3_price:.8f}")

    # VÃ©rification des TP basÃ©e sur le prix MAX atteint (historique + actuel)
    # AVEC TOLÃ‰RANCE pour Ã©viter problÃ¨mes d'arrondi
    if tp_reached(prix_max_atteint, tp3_price):
        tp_hit.extend(["TP1", "TP2", "TP3"])
        tp_gains["TP1"] = ((tp1_price - entry_price) / entry_price) * 100
        tp_gains["TP2"] = ((tp2_price - entry_price) / entry_price) * 100
        tp_gains["TP3"] = ((tp3_price - entry_price) / entry_price) * 100
    elif tp_reached(prix_max_atteint, tp2_price):
        tp_hit.extend(["TP1", "TP2"])
        tp_gains["TP1"] = ((tp1_price - entry_price) / entry_price) * 100
        tp_gains["TP2"] = ((tp2_price - entry_price) / entry_price) * 100
    elif tp_reached(prix_max_atteint, tp1_price):
        tp_hit.append("TP1")
        tp_gains["TP1"] = ((tp1_price - entry_price) / entry_price) * 100

    # RÃˆGLE 2: VÃ©rifier si le prix est trop Ã©levÃ© pour re-entry (>20% depuis alerte initiale)
    hausse_depuis_alerte = ((current_price - entry_price) / entry_price) * 100
    prix_trop_eleve = hausse_depuis_alerte > 20.0

    # RÃˆGLE 5: Analyser la vÃ©locitÃ© du pump (protection pump parabolique)
    from datetime import datetime

    # Calculer le temps Ã©coulÃ© depuis l'alerte prÃ©cÃ©dente
    try:
        if isinstance(previous_alert.get('created_at'), str):
            created_at = datetime.strptime(previous_alert['created_at'], '%Y-%m-%d %H:%M:%S')
        else:
            created_at = previous_alert.get('created_at')

        temps_ecoule_heures = (datetime.now() - created_at).total_seconds() / 3600
    except:
        # Si erreur de parsing, estimer Ã  1h par dÃ©faut
        temps_ecoule_heures = 1.0

    # Ã‰viter division par zÃ©ro
    if temps_ecoule_heures < 0.01:  # Moins de 36 secondes
        temps_ecoule_heures = 0.01

    # Calculer la vÃ©locitÃ©: % de hausse par heure
    velocite_pump = hausse_depuis_alerte / temps_ecoule_heures

    # Classifier le type de pump
    pump_parabolique = False
    pump_tres_rapide = False
    type_pump = ""

    if velocite_pump > 100:  # >100% par heure = PARABOLIQUE
        type_pump = "PARABOLIQUE"
        pump_parabolique = True
    elif velocite_pump > 50:  # >50% par heure = TRÃˆS RAPIDE
        type_pump = "TRES_RAPIDE"
        pump_tres_rapide = True
    elif velocite_pump > 20:  # >20% par heure = RAPIDE
        type_pump = "RAPIDE"
    elif velocite_pump > 5:  # >5% par heure = NORMAL
        type_pump = "NORMAL"
    else:  # â‰¤5% par heure = LENT (sain)
        type_pump = "LENT"

    # RÃˆGLE 3: RÃ©Ã©valuer les conditions actuelles du marchÃ©
    log(f"   ğŸ” DEBUG avant evaluer_conditions_marche: pool_data={type(pool_data)}, score={score}, momentum={type(momentum)}, signal_1h={signal_1h}, signal_6h={signal_6h}")
    conditions_favorables, decision_marche, raisons_marche = evaluer_conditions_marche(
        pool_data, score, momentum, signal_1h, signal_6h
    )
    log(f"   ğŸ” DEBUG aprÃ¨s evaluer_conditions_marche: raisons_marche={type(raisons_marche)}")

    # RÃˆGLE 4: DÃ©cision finale
    raisons = []
    decision = ""
    nouveaux_niveaux = {}

    # CAS 1: Aucun TP atteint â†’ Ã‰valuation selon conditions (FIX BUG #3)
    if not tp_hit:
        # Ã‰valuer si c'est toujours une bonne opportunitÃ© d'entrÃ©e
        if conditions_favorables and score >= 70:
            decision = "ENTRER"
            raisons.append(f"Aucun TP atteint mais conditions excellentes (Score: {score})")
            raisons.append(f"ğŸ’¡ Si pas en position: ENTRER maintenant")
            raisons.append(f"ğŸ’¡ Si dÃ©jÃ  en position: MAINTENIR (pas de TP atteint)")
            log(f"   ğŸ” DEBUG AVANT extend bullish: raisons_marche type={type(raisons_marche)}, bullish type={type(raisons_marche.get('bullish') if isinstance(raisons_marche, dict) else 'N/A')}")
            raisons.extend(raisons_marche['bullish'][:3])
            log(f"   ğŸ” DEBUG APRÃˆS extend bullish")
        elif conditions_favorables and score >= 60:
            decision = "ATTENDRE"
            raisons.append(f"Aucun TP atteint, conditions moyennes (Score: {score})")
            raisons.append(f"ğŸ’¡ Si pas en position: ATTENDRE meilleure entrÃ©e")
            raisons.append(f"ğŸ’¡ Si dÃ©jÃ  en position: MAINTENIR position initiale")
        else:
            decision = "EVITER"
            raisons.append("Aucun TP atteint et conditions dÃ©favorables")
            raisons.append(f"ğŸ’¡ Si pas en position: Ã‰VITER")
            raisons.append(f"ğŸ’¡ Si en position: ConsidÃ©rer SORTIE si SL proche")
            if raisons_marche['bearish']:
                raisons.extend(raisons_marche['bearish'][:2])

    # CAS 2a: PUMP PARABOLIQUE â†’ SORTIR IMMÃ‰DIATEMENT (risque dump violent)
    elif pump_parabolique and tp_hit:
        decision = "SORTIR"
        raisons.append(f"âœ… {', '.join(tp_hit)} atteint(s) (+{hausse_depuis_alerte:.1f}%)")
        raisons.append(f"ğŸš¨ PUMP PARABOLIQUE dÃ©tectÃ© ({velocite_pump:.0f}%/h)")
        raisons.append(f"âš ï¸ Risque de dump violent - SÃ‰CURISER IMMÃ‰DIATEMENT")
        raisons.append("ğŸ’° Prendre les profits maintenant avant le retournement")

    # CAS 2b: TP atteint(s) + prix trop Ã©levÃ© â†’ Ne pas re-rentrer
    elif prix_trop_eleve:
        decision = "SORTIR"
        raisons.append(f"âœ… {', '.join(tp_hit)} atteint(s) (+{hausse_depuis_alerte:.1f}%)")
        raisons.append(f"âš ï¸ Prix trop Ã©levÃ© pour re-entry (+{hausse_depuis_alerte:.1f}% depuis alerte initiale)")
        raisons.append("ğŸ’° SÃ©curiser les gains dÃ©jÃ  rÃ©alisÃ©s")

    # CAS 3a: PUMP TRÃˆS RAPIDE + conditions favorables â†’ Nouveaux niveaux TRÃˆS SERRÃ‰S
    elif pump_tres_rapide and conditions_favorables and tp_hit:
        decision = "NOUVEAUX_NIVEAUX"
        raisons.append(f"âœ… {', '.join(tp_hit)} atteint(s)")
        for tp_name, gain in tp_gains.items():
            raisons.append(f"   {tp_name}: +{gain:.1f}%")
        raisons.append(f"âš¡ Pump trÃ¨s rapide ({velocite_pump:.0f}%/h)")
        raisons.append(f"ğŸš€ Conditions encore favorables ({decision_marche})")
        raisons.append("âš ï¸ SL TRÃˆS SERRÃ‰ (-3%) car pump rapide")

        # SL TRÃˆS SERRÃ‰ Ã  97% pour pump trÃ¨s rapide
        nouveaux_niveaux = {
            'entry_price': current_price,
            'stop_loss_price': current_price * 0.97,  # -3% au lieu de -5%
            'stop_loss_percent': -3.0,
            'tp1_price': current_price * 1.05,
            'tp1_percent': 5.0,
            'tp2_price': current_price * 1.10,
            'tp2_percent': 10.0,
            'tp3_price': current_price * 1.15,
            'tp3_percent': 15.0
        }

    # CAS 3b: TP atteint(s) + conditions favorables â†’ Nouveaux niveaux
    elif conditions_favorables:
        decision = "NOUVEAUX_NIVEAUX"
        raisons.append(f"âœ… {', '.join(tp_hit)} atteint(s)")
        for tp_name, gain in tp_gains.items():
            raisons.append(f"   {tp_name}: +{gain:.1f}%")
        raisons.append(f"ğŸš€ Conditions encore favorables ({decision_marche})")
        raisons.extend(raisons_marche['bullish'][:3])  # Top 3 raisons haussiÃ¨res

        # Afficher type de pump
        if type_pump == "LENT":
            raisons.append(f"âœ… Pump sain ({velocite_pump:.1f}%/h) - Progression stable")

        # Calculer NOUVEAUX niveaux depuis le prix actuel
        # SL plus serrÃ© Ã  95% (car dÃ©jÃ  en profit)
        nouveaux_niveaux = {
            'entry_price': current_price,
            'stop_loss_price': current_price * 0.95,
            'stop_loss_percent': -5.0,
            'tp1_price': current_price * 1.05,
            'tp1_percent': 5.0,
            'tp2_price': current_price * 1.10,
            'tp2_percent': 10.0,
            'tp3_price': current_price * 1.15,
            'tp3_percent': 15.0
        }

    # CAS 4: TP atteint(s) + conditions neutres/baissiÃ¨res â†’ SÃ©curiser
    else:
        decision = "SECURISER_HOLD"
        raisons.append(f"âœ… {', '.join(tp_hit)} atteint(s)")
        for tp_name, gain in tp_gains.items():
            raisons.append(f"   {tp_name}: +{gain:.1f}%")
        raisons.append(f"âš ï¸ Conditions actuelles: {decision_marche}")
        raisons.extend(raisons_marche['bearish'][:2])  # Top 2 raisons baissiÃ¨res
        raisons.append("ğŸ’¡ Trailing stop Ã  -5% recommandÃ© pour sÃ©curiser")

    return {
        'decision': decision,
        'tp_hit': tp_hit,
        'tp_gains': tp_gains,
        'prix_trop_eleve': prix_trop_eleve,
        'conditions_favorables': conditions_favorables,
        'raisons': raisons,
        'nouveaux_niveaux': nouveaux_niveaux,
        'hausse_depuis_alerte': hausse_depuis_alerte,
        'velocite_pump': velocite_pump,
        'type_pump': type_pump,
        'temps_ecoule_heures': temps_ecoule_heures
    }

# ============================================
# GÃ‰NÃ‰RATION ALERTE COMPLÃˆTE
# ============================================

def generer_alerte_complete(pool_data: Dict, score: int, base_score: int, momentum_bonus: int,
                            momentum: Dict, multi_pool_data: Dict, signals: List[str],
                            resistance_data: Dict, whale_analysis: Dict = None, is_first_alert: bool = True,
                            tracker: 'AlertTracker' = None) -> tuple:
    """GÃ©nÃ¨re alerte ultra-complÃ¨te avec toutes les donnÃ©es.

    Args:
        tracker: Instance d'AlertTracker pour accÃ©der Ã  l'historique (optionnel)

    Returns:
        tuple: (message_texte, donnees_regle5_dict)
    """

    # Initialiser les donnÃ©es RÃˆGLE 5 par dÃ©faut
    regle5_data = {
        'velocite_pump': 0,
        'type_pump': 'UNKNOWN',
        'decision_tp_tracking': None,
        'temps_depuis_alerte_precedente': 0,
        'is_alerte_suivante': 0
    }

    name = pool_data["name"]
    base_token = pool_data["base_token_name"]
    price = pool_data["price_usd"]
    vol_24h = pool_data["volume_24h"]
    vol_6h = pool_data["volume_6h"]
    vol_1h = pool_data["volume_1h"]
    liq = pool_data["liquidity"]
    pct_24h = pool_data["price_change_24h"]
    pct_6h = pool_data["price_change_6h"]
    pct_3h = pool_data["price_change_3h"]
    pct_1h = pool_data["price_change_1h"]
    age = pool_data["age_hours"]
    txns = pool_data["total_txns"]
    buys = pool_data["buys_24h"]
    sells = pool_data["sells_24h"]
    buys_1h = pool_data["buys_1h"]
    sells_1h = pool_data["sells_1h"]
    network_id = pool_data["network"]  # ID original pour le lien
    network_display = get_network_display_name(network_id)  # Nom lisible pour affichage
    ratio_vol_liq = (vol_24h / liq * 100) if liq > 0 else 0
    buy_ratio_24h = buys / sells if sells > 0 else 1.0
    buy_ratio_1h = buys_1h / sells_1h if sells_1h > 0 else 1.0

    # Initialiser les signaux volume (seront dÃ©finis dans l'analyse volume)
    signal_1h = None
    signal_6h = None

    # Emojis score
    if score >= 80:
        score_emoji = "â­ï¸â­ï¸â­ï¸â­ï¸"
        score_label = "EXCELLENT"
    elif score >= 70:
        score_emoji = "â­ï¸â­ï¸â­ï¸"
        score_label = "TRÃˆS BON"
    elif score >= 60:
        score_emoji = "â­ï¸â­ï¸"
        score_label = "BON"
    elif score >= 50:
        score_emoji = "â­ï¸"
        score_label = "MOYEN"
    else:
        score_emoji = ""
        score_label = "FAIBLE"

    # ========== CONSTRUCTION ALERTE ==========
    # Titre diffÃ©rent selon s'il s'agit de la premiÃ¨re alerte ou d'une mise Ã  jour
    if is_first_alert:
        txt = f"\nğŸ†• *Nouvelle opportunitÃ© sur le token {base_token}*\n"
    else:
        txt = f"\nğŸ”„ *Nouvelle analyse sur le token {base_token}*\n"
    txt += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
    txt += f"ğŸ’ {name}\n"
    txt += f"â›“ï¸ Blockchain: {network_display}\n\n"

    # SCORE + CONFIANCE (NOUVEAU)
    confidence = calculate_confidence_score(pool_data)
    txt += f"ğŸ¯ *SCORE: {score}/100 {score_emoji} {score_label}*\n"
    txt += f"   Base: {base_score} | Momentum: {momentum_bonus:+d}"

    # Afficher whale score si disponible
    if whale_analysis:
        whale_score = whale_analysis['whale_score']
        if whale_score != 0:
            txt += f" | Whale: {whale_score:+d}"

    txt += f"\nğŸ“Š Confiance: {confidence}% (fiabilitÃ© donnÃ©es)\n"

    # ===== V3: TIER DE CONFIANCE BACKTEST =====
    tier = calculate_confidence_tier(pool_data)
    tier_emojis = {
        "ULTRA_HIGH": "ğŸ’ğŸ’ğŸ’",
        "HIGH": "ğŸ’ğŸ’",
        "MEDIUM": "ğŸ’",
        "LOW": "âšª",
        "VERY_LOW": "âš«"
    }
    tier_labels = {
        "ULTRA_HIGH": "ULTRA HIGH (Watchlist - 77-100% WR historique)",
        "HIGH": "HIGH (35-50% WR attendu)",
        "MEDIUM": "MEDIUM (25-30% WR attendu)",
        "LOW": "LOW (15-20% WR attendu)",
        "VERY_LOW": "VERY LOW (<15% WR attendu)"
    }
    tier_emoji = tier_emojis.get(tier, "âšª")
    tier_label = tier_labels.get(tier, "UNKNOWN")

    txt += f"ğŸ–ï¸ *TIER V3: {tier_emoji} {tier_label}*\n"

    # Afficher les raisons de filtrage V3 (si disponibles)
    v3_reasons = pool_data.get('v3_filter_reasons', [])
    if v3_reasons:
        # Afficher seulement les raisons positives (succÃ¨s)
        positive_reasons = [r.replace('âœ“ ', '') for r in v3_reasons if r.startswith('âœ“')]
        if positive_reasons:
            txt += f"   V3 Checks: {' | '.join(positive_reasons[:3])}\n"  # Max 3 raisons

    txt += "\n"

    # NOUVEAU: Section WHALE ACTIVITY (FIX BUG #5 - Toujours afficher si whale_score != 0)
    if whale_analysis:
        whale_score_val = whale_analysis.get('whale_score', 0)
        pattern = whale_analysis.get('pattern', 'NORMAL')
        signals = whale_analysis.get('signals', [])

        # Afficher si whale_score != 0 OU si pattern != NORMAL OU si signals non vide
        if whale_score_val != 0 or pattern != 'NORMAL' or signals:
            concentration_risk = whale_analysis['concentration_risk']
            buyers_1h = whale_analysis['buyers_1h']
            sellers_1h = whale_analysis['sellers_1h']
            avg_buys = whale_analysis['avg_buys_per_buyer']
            avg_sells = whale_analysis.get('avg_sells_per_seller', 0)

            # Emoji selon pattern
            if pattern == 'WHALE_MANIPULATION':
                pattern_emoji = "ğŸ‹"
                pattern_label = "WHALE MANIPULATION"
            elif pattern == 'WHALE_SELLING':
                pattern_emoji = "ğŸš¨"
                pattern_label = "WHALE SELLING"
            elif pattern == 'DISTRIBUTED_BUYING':
                pattern_emoji = "âœ…"
                pattern_label = "ACCUMULATION DISTRIBUÃ‰E"
            elif pattern == 'DISTRIBUTED_SELLING':
                pattern_emoji = "âš ï¸"
                pattern_label = "SELLING PRESSURE"
            else:
                # Pattern NORMAL mais whale_score != 0 (ex: concentration 24h)
                pattern_emoji = "ğŸ“Š"
                pattern_label = "WHALE ACTIVITY"

            txt += f"\n{pattern_emoji} *{pattern_label}*\n"
            txt += f"   Buyers: {buyers_1h} | Sellers: {sellers_1h}\n"
            txt += f"   Avg buys/buyer: {avg_buys:.1f}x"
            if avg_sells > 0:
                txt += f" | Avg sells/seller: {avg_sells:.1f}x"
            txt += f"\n   Risque concentration: {concentration_risk}\n"

            # Afficher les signaux si disponibles
            if signals:
                txt += f"   Signaux: {', '.join(signals[:2])}\n"

    txt += "\n"

    # ========== ANALYSE TP TRACKING (pour alertes suivantes) ==========
    if not is_first_alert and tracker is not None:
        token_address = pool_data.get("pool_address", "")
        previous_alert = tracker.get_last_alert_for_token(token_address)

        if previous_alert:
            # PrÃ©-calculer les signaux volume pour l'analyse
            vol_24h_avg = vol_24h / 24
            vol_6h_avg = vol_6h / 6 if vol_6h > 0 else 0
            ratio_1h_vs_6h = (vol_1h / vol_6h_avg) if vol_6h_avg > 0 else 0
            ratio_6h_vs_24h = (vol_6h_avg / vol_24h_avg) if vol_24h_avg > 0 else 0

            # DÃ©terminer signaux
            if ratio_1h_vs_6h >= 2.0:
                signal_1h = "FORTE_ACCELERATION"
            elif ratio_1h_vs_6h >= 1.5:
                signal_1h = "ACCELERATION"
            elif ratio_1h_vs_6h <= 0.3:
                signal_1h = "FORT_RALENTISSEMENT"
            elif ratio_1h_vs_6h <= 0.5:
                signal_1h = "RALENTISSEMENT"
            else:
                signal_1h = "STABLE"

            if ratio_6h_vs_24h >= 1.8:
                signal_6h = "PUMP_EN_COURS"
            elif ratio_6h_vs_24h >= 1.3:
                signal_6h = "HAUSSE_PROGRESSIVE"
            elif ratio_6h_vs_24h <= 0.7:
                signal_6h = "BAISSE_TENDANCIELLE"
            else:
                signal_6h = "STABLE"

            # Analyser TP tracking (passer le tracker pour vÃ©rifier le prix MAX atteint)
            analyse_tp = analyser_alerte_suivante(
                previous_alert, price, pool_data, score, momentum, signal_1h, signal_6h, tracker
            )
            log(f"   ğŸ” DEBUG RETOUR analyser_alerte_suivante: decision={analyse_tp.get('decision') if analyse_tp else None}, type={type(analyse_tp)}")

            # VALIDATION: VÃ©rifier que analyse_tp est un dict valide
            if not analyse_tp or not isinstance(analyse_tp, dict):
                log(f"   âš ï¸ analyse_tp invalide: {type(analyse_tp)}")
                # Ne pas afficher la section TP tracking si erreur
            elif analyse_tp['decision'] == 'ERROR':
                # VÃ©rifier si l'analyse a Ã©chouÃ© (decision == 'ERROR')
                log(f"   âš ï¸ Analyse TP tracking Ã©chouÃ©e, skip section suivi")
                # Ne pas afficher la section TP tracking si erreur
            else:
                # Mettre Ã  jour les donnÃ©es RÃˆGLE 5
                regle5_data = {
                    'velocite_pump': analyse_tp['velocite_pump'],
                    'type_pump': analyse_tp['type_pump'],
                    'decision_tp_tracking': analyse_tp['decision'],
                    'temps_depuis_alerte_precedente': analyse_tp['temps_ecoule_heures'],
                    'is_alerte_suivante': 1
                }

                # Afficher section TP TRACKING
                txt += f"â”â”â” SUIVI ALERTE PRÃ‰CÃ‰DENTE â”â”â”\n"
                entry_prev = previous_alert.get('entry_price', previous_alert.get('price_at_alert', 0))
                txt += f"ğŸ“ Entry prÃ©cÃ©dente: {format_price(entry_prev)}\n"
                txt += f"ğŸ’° Prix actuel: {format_price(price)} ({analyse_tp['hausse_depuis_alerte']:+.1f}%)\n"

                # Afficher vÃ©locitÃ© du pump
                temps_h = analyse_tp['temps_ecoule_heures']
                velocite = analyse_tp['velocite_pump']
                type_pump = analyse_tp['type_pump']

                if temps_h < 1:
                    temps_display = f"{temps_h * 60:.0f} min"
                else:
                    temps_display = f"{temps_h:.1f}h"

                # Emoji selon type de pump
                if type_pump == "PARABOLIQUE":
                    pump_emoji = "ğŸš¨"
                    pump_label = "PARABOLIQUE (DANGER)"
                elif type_pump == "TRES_RAPIDE":
                    pump_emoji = "âš¡"
                    pump_label = "TRÃˆS RAPIDE"
                elif type_pump == "RAPIDE":
                    pump_emoji = "ğŸ”¥"
                    pump_label = "RAPIDE"
                elif type_pump == "NORMAL":
                    pump_emoji = "ğŸ“ˆ"
                    pump_label = "NORMAL"
                else:  # LENT
                    pump_emoji = "âœ…"
                    pump_label = "SAIN"

                txt += f"â±ï¸ Temps Ã©coulÃ©: {temps_display} | {pump_emoji} VÃ©locitÃ©: {velocite:.0f}%/h ({pump_label})\n"

                # Afficher Prix MAX atteint (CRITIQUE pour comprendre dÃ©tection TP)
                if tracker is not None and 'previous_alert' in locals() and previous_alert:
                    alert_id = previous_alert.get('id', 0)
                    prix_max_db = tracker.get_highest_price_for_alert(alert_id) if alert_id > 0 else None
                    prix_max_display = max(prix_max_db or 0, price)

                    if prix_max_display > 0:
                        entry_price_ref = previous_alert.get('entry_price', price)
                        gain_max = ((prix_max_display - entry_price_ref) / entry_price_ref) * 100
                        txt += f"ğŸ“ˆ Prix MAX atteint: {format_price(prix_max_display)} (+{gain_max:.1f}%)\n"

                # Afficher TP atteints (basÃ© sur Prix MAX, pas prix actuel)
                if analyse_tp['tp_hit']:
                    txt += f"âœ… *TP ATTEINTS:* {', '.join(analyse_tp['tp_hit'])}\n"
                    for tp_name, gain in analyse_tp['tp_gains'].items():
                        txt += f"   {tp_name}: +{gain:.1f}%\n"
                else:
                    txt += f"â³ Aucun TP atteint pour le moment\n"

                txt += f"\nğŸ¯ *DÃ‰CISION: {analyse_tp['decision']}*\n"

                # Afficher raisons
                for raison in analyse_tp['raisons']:
                    txt += f"{raison}\n"

                txt += "\n"

    # PRIX & MOMENTUM
    txt += f"â”â”â” PRIX & MOMENTUM â”â”â”\n"
    txt += f"ğŸ’° Prix: {format_price(price)}\n"

    # Multi-timeframe avec analyse de tendance
    txt += f"ğŸ“Š "
    txt += f"24h: {pct_24h:+.1f}% "
    if pct_6h != 0:
        txt += f"| 6h: {pct_6h:+.1f}% "
    if pct_3h != 0:
        txt += f"| 3h: {pct_3h:+.1f}% "
    if pct_1h != 0:
        emoji_1h = "ğŸš€" if pct_1h > 5 else ("ğŸŸ¢" if pct_1h > 0 else "ğŸ”´")
        txt += f"| 1h: {pct_1h:+.1f}% {emoji_1h}"
    txt += "\n"

    # Analyse de la structure de tendance (NOUVEAU)
    if pct_6h != 0 and pct_3h != 0 and pct_1h != 0:
        # DÃ©terminer si accÃ©lÃ©ration haussiÃ¨re ou essoufflement
        if pct_1h > pct_3h > pct_6h and pct_1h > 0:
            txt += f"ğŸ“ˆ Tendance: ACCÃ‰LÃ‰RATION HAUSSIÃˆRE ğŸ”¥\n"
        elif pct_6h > pct_3h > pct_1h and pct_6h > 0:
            txt += f"âš ï¸ Tendance: ESSOUFFLEMENT (sortie proche) ğŸ“‰\n"
        elif pct_1h < 0 < pct_3h < pct_6h:
            txt += f"ğŸ”„ Tendance: REPRISE aprÃ¨s correction (bon entry) âœ…\n"
        elif pct_1h < pct_3h < pct_6h and pct_1h < 0:
            txt += f"ğŸ”´ Tendance: DÃ‰CÃ‰LÃ‰RATION BAISSIÃˆRE âš ï¸\n"

    # RÃ©sistance
    if resistance_data and resistance_data.get("resistance"):
        txt += f"ğŸ¯ RÃ©sistance: {format_price(resistance_data['resistance'])} "
        txt += f"(+{resistance_data['resistance_dist_pct']:.1f}%)\n"

    txt += "\n"

    # ACTIVITÃ‰
    txt += f"â”â”â” ACTIVITÃ‰ â”â”â”\n"
    txt += f"ğŸ“Š Vol 24h: ${vol_24h/1000:.0f}K\n"

    # Analyse de l'Ã©volution du volume MULTI-NIVEAUX (NOUVEAU)
    if vol_24h > 0 and vol_6h > 0 and vol_1h > 0:
        # Calculer les moyennes horaires
        vol_24h_avg = vol_24h / 24  # Volume moyen par heure sur 24h
        vol_6h_avg = vol_6h / 6     # Volume moyen par heure sur 6h

        # Ratios d'accÃ©lÃ©ration
        ratio_1h_vs_6h = (vol_1h / vol_6h_avg) if vol_6h_avg > 0 else 0
        ratio_6h_vs_24h = (vol_6h_avg / vol_24h_avg) if vol_24h_avg > 0 else 0

        # ANALYSE DOUBLE NIVEAU pour dÃ©tecter les meilleurs setups

        # Niveau 1: Court terme (1h vs 6h)
        if ratio_1h_vs_6h >= 2.0:
            signal_1h = "FORTE_ACCELERATION"
            emoji_1h = "ğŸ”¥"
            text_1h = f"FORTE ACCÃ‰LÃ‰RATION ({ratio_1h_vs_6h:.1f}x)"
        elif ratio_1h_vs_6h >= 1.5:
            signal_1h = "ACCELERATION"
            emoji_1h = "ğŸ“ˆ"
            text_1h = f"ACCÃ‰LÃ‰RATION ({ratio_1h_vs_6h:.1f}x)"
        elif ratio_1h_vs_6h <= 0.5:
            signal_1h = "RALENTISSEMENT"
            emoji_1h = "âš ï¸"
            text_1h = f"RALENTISSEMENT ({ratio_1h_vs_6h:.1f}x)"
        elif ratio_1h_vs_6h <= 0.3:
            signal_1h = "FORT_RALENTISSEMENT"
            emoji_1h = "ğŸ”´"
            text_1h = f"FORT RALENTISSEMENT ({ratio_1h_vs_6h:.1f}x)"
        else:
            signal_1h = "STABLE"
            emoji_1h = "â¡ï¸"
            text_1h = f"STABLE ({ratio_1h_vs_6h:.1f}x)"

        # Niveau 2: Moyen terme (6h vs 24h)
        if ratio_6h_vs_24h >= 1.8:
            signal_6h = "PUMP_EN_COURS"
            emoji_6h = "ğŸš€"
            text_6h = f"Pump en cours ({ratio_6h_vs_24h:.1f}x)"
        elif ratio_6h_vs_24h >= 1.3:
            signal_6h = "HAUSSE_PROGRESSIVE"
            emoji_6h = "ğŸ“Š"
            text_6h = f"Hausse progressive ({ratio_6h_vs_24h:.1f}x)"
        elif ratio_6h_vs_24h <= 0.7:
            signal_6h = "BAISSE_TENDANCIELLE"
            emoji_6h = "ğŸ“‰"
            text_6h = f"Baisse tendancielle ({ratio_6h_vs_24h:.1f}x)"
        else:
            signal_6h = "STABLE"
            emoji_6h = "â¡ï¸"
            text_6h = f"Normal ({ratio_6h_vs_24h:.1f}x)"

        # VERDICT FINAL combinant les deux niveaux
        txt += f"ğŸ“Š Volume Multi-Timeframe:\n"
        txt += f"   Court terme (1h): {emoji_1h} {text_1h}\n"
        txt += f"   Moyen terme (6h): {emoji_6h} {text_6h}\n"

        # PATTERN GAGNANTS (basÃ© sur backtest)
        if signal_1h in ["FORTE_ACCELERATION", "ACCELERATION"] and signal_6h == "PUMP_EN_COURS":
            txt += f"âœ… PATTERN: ENTRÃ‰E IDÃ‰ALE - Pump actif + accÃ©lÃ©ration rÃ©cente ğŸ¯\n"
        elif signal_1h == "FORTE_ACCELERATION" and signal_6h in ["HAUSSE_PROGRESSIVE", "STABLE"]:
            txt += f"âœ… PATTERN: BON ENTRY - Nouveau pump qui dÃ©marre ğŸŸ¢\n"
        elif signal_1h in ["RALENTISSEMENT", "FORT_RALENTISSEMENT"] and signal_6h == "PUMP_EN_COURS":
            txt += f"âš ï¸ PATTERN: SORTIE PROCHE - Volume qui faiblit (essoufflement) ğŸšª\n"
        elif signal_1h == "STABLE" and signal_6h == "PUMP_EN_COURS":
            txt += f"â¸ï¸ PATTERN: CONSOLIDATION - Pause avant continuation possible\n"
        elif signal_1h in ["RALENTISSEMENT", "FORT_RALENTISSEMENT"]:
            txt += f"ğŸ”´ PATTERN: Ã‰VITER - Volume en chute libre âŒ\n"

        # Afficher dÃ©tails volumes
        txt += f"   Vol: 24h ${vol_24h/1000:.0f}K | 6h ${vol_6h/1000:.0f}K | 1h ${vol_1h/1000:.0f}K\n"

    # Volume spike ?
    elif vol_1h > 0:
        vol_1h_normalized = vol_1h * 24
        if vol_1h_normalized > vol_24h * 1.3:
            spike = ((vol_1h_normalized / vol_24h) - 1) * 100
            txt += f"âš¡ Vol 1h: ${vol_1h/1000:.0f}K (x{vol_1h_normalized/vol_24h:.1f} activitÃ©!) ğŸ”¥\n"
        else:
            txt += f"ğŸ“‰ Vol 1h: ${vol_1h/1000:.0f}K\n"

    txt += f"ğŸ’§ LiquiditÃ©: ${liq/1000:.0f}K\n"

    # Transactions 24h - Format explicite avec estimation traders (NOUVEAU)
    txt += f"ğŸ”„ Transactions 24h: {txns}\n"
    # Estimation traders: moyenne 2-3 tx par trader
    traders_estimate = int(txns / 2.5)  # Estimation conservative
    txt += f"ğŸ‘¥ Traders estimÃ©s: ~{traders_estimate} (basÃ© sur txns)\n"
    buys_pct = (buys / txns * 100) if txns > 0 else 0
    sells_pct = (sells / txns * 100) if txns > 0 else 0
    txt += f"   ğŸŸ¢ ACHATS: {buys} ({buys_pct:.0f}%)\n"
    txt += f"   ğŸ”´ VENTES: {sells} ({sells_pct:.0f}%)\n"

    # Pression dominante
    if buy_ratio_24h >= 1.0:
        txt += f"   âš–ï¸ Pression: ACHETEURS dominent (ratio {buy_ratio_24h:.2f})\n"
    elif buy_ratio_24h >= 0.8:
        txt += f"   âš–ï¸ Pression: Ã‰QUILIBRÃ‰E (ratio {buy_ratio_24h:.2f})\n"
    else:
        txt += f"   âš–ï¸ Pression: VENDEURS dominent (ratio {buy_ratio_24h:.2f})\n"

    # Pression 1h (si diffÃ©rente)
    if buys_1h > 0 and sells_1h > 0 and abs(buy_ratio_1h - buy_ratio_24h) > 0.1:
        txt += f"\nğŸ“Š Pression 1h:\n"
        buys_1h_pct = (buys_1h / (buys_1h + sells_1h) * 100)
        sells_1h_pct = (sells_1h / (buys_1h + sells_1h) * 100)
        txt += f"   ğŸŸ¢ ACHATS: {buys_1h} ({buys_1h_pct:.0f}%)"

        if buy_ratio_1h > buy_ratio_24h:
            txt += f" â¬†ï¸\n"
        else:
            txt += f" â¬‡ï¸\n"

        txt += f"   ğŸ”´ VENTES: {sells_1h} ({sells_1h_pct:.0f}%)"

        if buy_ratio_1h > buy_ratio_24h:
            txt += f" â¬‡ï¸\n"
        else:
            txt += f" â¬†ï¸\n"

        # Analyse de la tendance de pression (focus sur l'Ã©volution, pas les absolus)
        ratio_change = buy_ratio_1h - buy_ratio_24h

        if ratio_change > 0.1:  # Pression acheteuse augmente significativement
            txt += f"   âœ… ACHETEURS prennent le contrÃ´le ! (+{ratio_change:.1%})\n"
        elif ratio_change < -0.1:  # Pression vendeuse augmente significativement
            txt += f"   âš ï¸ VENDEURS prennent le contrÃ´le ! ({ratio_change:.1%})\n"
        else:  # Pression stable
            if buy_ratio_1h >= 0.75:
                txt += f"   â¡ï¸ Pression ACHETEUSE stable ({buy_ratio_1h:.0%})\n"
            elif buy_ratio_1h <= 0.55:
                txt += f"   â¡ï¸ Pression VENDEUSE stable ({buy_ratio_1h:.0%})\n"
            else:
                txt += f"   â¡ï¸ Ã‰quilibre acheteurs/vendeurs ({buy_ratio_1h:.0%})\n"

    txt += f"\nâš¡ Vol/Liq: {ratio_vol_liq:.0f}%\n"
    txt += f"â° CrÃ©Ã© il y a {age:.0f}h\n\n"

    # MULTI-POOL (si applicable)
    if multi_pool_data.get("is_multi_pool"):
        txt += f"â”â”â” MULTI-POOL â”â”â”\n"
        txt += f"ğŸŒ Pools actifs: {multi_pool_data['num_pools']}\n"
        txt += f"ğŸ“Š Volume total: ${multi_pool_data['total_volume']/1000:.0f}K\n"
        txt += f"ğŸ’§ LiquiditÃ© totale: ${multi_pool_data['total_liquidity']/1000:.0f}K\n"

        # DÃ©tail pools
        for activity in multi_pool_data['pool_activities']:
            txt += f"   â€¢ {activity['pair']}: {activity['vol_liq_pct']:.0f}% Vol/Liq\n"

        if multi_pool_data.get("is_weth_dominant"):
            txt += f"âš¡ WETH pool dominant = Smart money ğŸš€\n"
        txt += "\n"

    # SIGNAUX
    if signals:
        txt += f"â”â”â” SIGNAUX DÃ‰TECTÃ‰S â”â”â”\n"
        for signal in signals:
            txt += f"{signal}\n"
        txt += "\n"

    # Ã‰VALUATION DES CONDITIONS MARCHÃ‰ POUR DÃ‰CISION D'ENTRÃ‰E
    should_enter, decision, analysis_reasons = evaluer_conditions_marche(
        pool_data, score, momentum, signal_1h, signal_6h
    )

    # ACTION RECOMMANDÃ‰E - CONDITIONNELLE
    txt += f"â”â”â” ACTION RECOMMANDÃ‰E â”â”â”\n"

    # VÃ©rifier si on a une analyse TP avec nouveaux niveaux (alerte suivante)
    show_nouveaux_niveaux = (not is_first_alert and tracker is not None and
                             'analyse_tp' in locals() and
                             analyse_tp['decision'] == "NOUVEAUX_NIVEAUX")

    if show_nouveaux_niveaux:
        # âœ… NOUVEAUX NIVEAUX TP/SL (car TP prÃ©cÃ©dents atteints + conditions favorables)
        txt += f"ğŸš€ NOUVEAUX NIVEAUX - TP prÃ©cÃ©dents atteints !\n\n"

        nouveaux = analyse_tp['nouveaux_niveaux']
        entry_new = nouveaux['entry_price']
        stop_loss_new = nouveaux['stop_loss_price']
        tp1_new = nouveaux['tp1_price']
        tp2_new = nouveaux['tp2_price']
        tp3_new = nouveaux['tp3_price']

        txt += f"âš¡ Entry: {format_price(entry_new)} ğŸ¯\n"
        txt += f"ğŸ“ Limite entrÃ©e: {format_price(entry_new * 1.03)} (max +3%)\n"
        txt += f"ğŸ›‘ Stop loss: {format_price(stop_loss_new)} (-5%) âš¡ SL SERRÃ‰\n"
        txt += f"ğŸ¯ TP1 (50%): {format_price(tp1_new)} (+5%)\n"
        txt += f"ğŸ¯ TP2 (30%): {format_price(tp2_new)} (+10%)\n"
        txt += f"ğŸ¯ TP3 (20%): {format_price(tp3_new)} (+15%)\n"
        txt += f"ğŸ”„ Trail stop: -5% aprÃ¨s TP1\n\n"

        txt += f"ğŸ’¡ NOTE: SL plus serrÃ© (-5%) car dÃ©jÃ  en profit !\n\n"

    elif should_enter and decision == "BUY":
        # âœ… CONDITIONS FAVORABLES - Afficher Entry/SL/TP
        txt += f"âœ… SIGNAL D'ENTRÃ‰E VALIDÃ‰\n\n"

        # Afficher les raisons bullish
        if analysis_reasons['bullish']:
            txt += f"ğŸ“ˆ Signaux haussiers:\n"
            for reason in analysis_reasons['bullish']:
                txt += f"   â€¢ {reason}\n"
            txt += "\n"

        # FIX COHÃ‰RENCE TP: Si alerte suivante, utiliser TP de l'alerte ORIGINALE
        if not is_first_alert and tracker is not None and 'previous_alert' in locals() and previous_alert:
            # Utiliser les TP de la premiÃ¨re alerte (COHÃ‰RENCE)
            entry_original = previous_alert.get('entry_price', price)
            sl_original = previous_alert.get('stop_loss_price', price * 0.90)
            tp1_original = previous_alert.get('tp1_price', price * 1.05)
            tp2_original = previous_alert.get('tp2_price', price * 1.10)
            tp3_original = previous_alert.get('tp3_price', price * 1.15)

            txt += f"âš¡ Entry (alerte initiale): {format_price(entry_original)} ğŸ¯\n"
            txt += f"ğŸ“ Limite entrÃ©e: {format_price(entry_original * 1.03)} (max +3%)\n"
            txt += f"ğŸ›‘ Stop loss: {format_price(sl_original)} (-10%)\n"
            txt += f"ğŸ¯ TP1 (50%): {format_price(tp1_original)} (+5%)\n"
            txt += f"ğŸ¯ TP2 (30%): {format_price(tp2_original)} (+10%)\n"
            txt += f"ğŸ¯ TP3 (20%): {format_price(tp3_original)} (+15%)\n"
            txt += f"ğŸ”„ Trail stop: -5% aprÃ¨s TP1\n\n"
        else:
            # PremiÃ¨re alerte: calculer nouveaux TP depuis prix actuel
            price_max_entry = price * 1.03
            txt += f"âš¡ Entry: {format_price(price)} ğŸ¯\n"
            txt += f"ğŸ“ Limite entrÃ©e: {format_price(price_max_entry)} (max +3%)\n"

            # Stop loss
            stop_loss = price * 0.90
            txt += f"ğŸ›‘ Stop loss: {format_price(stop_loss)} (-10%)\n"

            # Take profits
            tp1 = price * 1.05
            tp2 = price * 1.10
            tp3 = price * 1.15
            txt += f"ğŸ¯ TP1 (50%): {format_price(tp1)} (+5%)\n"
            txt += f"ğŸ¯ TP2 (30%): {format_price(tp2)} (+10%)\n"
            txt += f"ğŸ¯ TP3 (20%): {format_price(tp3)} (+15%)\n"
            txt += f"ğŸ”„ Trail stop: -5% aprÃ¨s TP1\n\n"

    elif decision == "WAIT":
        # â¸ï¸ CONDITIONS INCERTAINES - Attendre
        txt += f"â¸ï¸ ATTENDRE - Conditions pas encore idÃ©ales\n\n"

        # Afficher les raisons
        if analysis_reasons['bearish']:
            txt += f"âš ï¸ Signaux nÃ©gatifs dÃ©tectÃ©s:\n"
            for reason in analysis_reasons['bearish']:
                txt += f"   â€¢ {reason}\n"
            txt += "\n"

        if analysis_reasons['bullish']:
            txt += f"âœ… Signaux positifs:\n"
            for reason in analysis_reasons['bullish']:
                txt += f"   â€¢ {reason}\n"
            txt += "\n"

        txt += f"ğŸ’¡ RECOMMANDATION:\n"
        txt += f"   â€¢ Surveiller l'Ã©volution du volume et du prix\n"
        txt += f"   â€¢ Attendre confirmation d'une tendance haussiÃ¨re claire\n"
        txt += f"   â€¢ Entrer si le volume accÃ©lÃ¨re et la pression acheteuse augmente\n"
        txt += f"   â€¢ Risque modÃ©rÃ© - Prudence recommandÃ©e\n\n"

    else:  # EXIT
        # ğŸš« CONDITIONS DÃ‰FAVORABLES - Ne pas entrer / Sortir
        txt += f"ğŸš« PAS D'ENTRÃ‰E - Sortie ou Ã©viter le marchÃ©\n\n"

        # Afficher les raisons bearish
        if analysis_reasons['bearish']:
            txt += f"ğŸ”´ Raisons de sortie/Ã©viter:\n"
            for reason in analysis_reasons['bearish']:
                txt += f"   â€¢ {reason}\n"
            txt += "\n"

        # Afficher les points positifs s'il y en a
        if analysis_reasons['bullish']:
            txt += f"âš ï¸ Points positifs (insuffisants):\n"
            for reason in analysis_reasons['bullish']:
                txt += f"   â€¢ {reason}\n"
            txt += "\n"

        txt += f"ğŸ’¡ RECOMMANDATION:\n"

        # DÃ©terminer si c'est un pump qui s'essouffle ou un token Ã  Ã©viter
        is_essoufflement = any("SORTIE" in r or "Essoufflement" in r or "DÃ©cÃ©lÃ©ration" in r for r in analysis_reasons['bearish'])
        is_volume_problem = any("Ã‰VITER" in r or "RALENTISSEMENT" in r or "chute" in r for r in analysis_reasons['bearish'])

        if is_essoufflement:
            txt += f"   â€¢ âš ï¸ SORTIR si vous Ãªtes en position (pump s'essouffle)\n"
            txt += f"   â€¢ NE PAS ENTRER - Momentum en dÃ©cÃ©lÃ©ration\n"
            txt += f"   â€¢ Attendre un Ã©ventuel rebound seulement si volume se stabilise\n"
            txt += f"   â€¢ Risque Ã©levÃ© de correction\n"
        elif is_volume_problem:
            txt += f"   â€¢ ğŸ”´ NE PAS ENTRER - Volume en chute\n"
            txt += f"   â€¢ Ã‰viter ce token pour le moment\n"
            txt += f"   â€¢ Chercher d'autres opportunitÃ©s avec volume sain\n"
            txt += f"   â€¢ Rebound peu probable sans nouvelle impulsion\n"
        else:
            txt += f"   â€¢ ğŸš« Conditions actuelles dÃ©favorables\n"
            txt += f"   â€¢ NE PAS ENTRER tant que la situation ne s'amÃ©liore pas\n"
            txt += f"   â€¢ Surveiller pour un Ã©ventuel rebound avec:\n"
            txt += f"     - Reprise du volume\n"
            txt += f"     - Augmentation de la pression acheteuse\n"
            txt += f"     - Momentum redevenant positif\n"

        txt += "\n"

    # RISQUES
    txt += f"â”â”â” RISQUES â”â”â”\n"
    if age < 24:
        txt += f"âš ï¸ TrÃ¨s jeune ({age:.0f}h) - VolatilitÃ© Ã©levÃ©e\n"
    elif age > 72:
        txt += f"âš ï¸ Age: {age:.0f}h (exit window passÃ©e?)\n"

    if pct_24h < -15:
        txt += f"âš ï¸ Variation 24h nÃ©gative ({pct_24h:.1f}%) - Risque re-dump\n"

    if liq >= 500000:
        txt += f"âœ… LiquiditÃ© solide (${liq/1000:.0f}K) - Faible risque rug\n"
    elif liq >= 200000:
        txt += f"âš ï¸ LiquiditÃ© moyenne (${liq/1000:.0f}K) - Prudence\n"
    else:
        txt += f"ğŸš¨ LiquiditÃ© faible (${liq/1000:.0f}K) - Risque Ã©levÃ©\n"

    txt += f"\nğŸ”— https://geckoterminal.com/{network_id.lower()}/pools/{pool_data['pool_address']}\n"

    return txt, regle5_data

# ============================================
# SCAN PRINCIPAL
# ============================================
def scan_geckoterminal():
    """Scan GeckoTerminal avec analyse avancÃ©e."""

    log("=" * 80)
    log("ğŸ¦ GECKOTERMINAL SCANNER V3.2.5 - DASHBOARD + Liquidity Quality Check")
    log("=" * 80)

    all_pools = []

    # Statistiques sources de liquiditÃ©
    liquidity_stats = {
        'reserve_in_usd': 0,
        'fdv_usd(10%)': 0,
        'market_cap(15%)': 0,
        'volume_24h(x5)': 0,
        'none': 0
    }

    # Collecter tous les pools
    for network in NETWORKS:
        log(f"\nğŸ” Scan rÃ©seau: {network.upper()}")

        # Trending pools - 1 page seulement (20 pools)
        trending = get_trending_pools(network)
        if trending:
            for pool in trending:
                pool_data = parse_pool_data(pool, network, liquidity_stats)
                if pool_data and pool_data["age_hours"] <= MAX_TOKEN_AGE_HOURS:
                    all_pools.append(pool_data)
            log(f"   ğŸ“Š {len(trending)} pools trending trouvÃ©s")

        time.sleep(2)

        # New pools - 1 page seulement (20 pools)
        new_pools = get_new_pools(network)
        if new_pools:
            for pool in new_pools:
                pool_data = parse_pool_data(pool, network, liquidity_stats)
                if pool_data and pool_data["age_hours"] <= MAX_TOKEN_AGE_HOURS:
                    all_pools.append(pool_data)
            log(f"   ğŸ†• {len(new_pools)} nouveaux pools trouvÃ©s")

        time.sleep(2)

    log(f"\nğŸ“Š Total pools collectÃ©s: {len(all_pools)}")

    # Mettre Ã  jour historique (seulement buy ratio)
    for pool_data in all_pools:
        update_buy_ratio_history(pool_data)

    # NOUVEAU: Mettre Ã  jour le prix MAX en temps rÃ©el pour TOUS les tokens trackÃ©s
    # CRITIQUE pour backtesting : capture les pics de prix entre chaque scan
    if alert_tracker is not None:
        for pool_data in all_pools:
            token_address = pool_data.get('token_address')
            current_price = pool_data.get('price', 0)

            if token_address and current_price > 0:
                # VÃ©rifier si ce token a une alerte active
                previous_alert = alert_tracker.get_last_alert_for_token(token_address)
                if previous_alert:
                    alert_id = previous_alert.get('id')
                    # Mettre Ã  jour le prix MAX en DB
                    alert_tracker.update_price_max_realtime(alert_id, current_price)

    # Grouper par token
    grouped = group_pools_by_token(all_pools)

    log(f"ğŸ”— Tokens uniques dÃ©tectÃ©s: {len(grouped)}")

    # Analyser chaque token
    opportunities = []
    tokens_rejected = 0  # Initialiser ici pour Ã©viter UnboundLocalError

    for base_token, pools in grouped.items():
        # Multi-pool analysis
        multi_pool_data = analyze_multi_pool(pools)

        # Analyser chaque pool
        for pool_data in pools:
            # Momentum - SIMPLIFIÃ‰: depuis API directement
            momentum = get_price_momentum_from_api(pool_data)

            # RÃ©sistance - SIMPLIFIÃ‰: calcul basique
            resistance_data = find_resistance_simple(pool_data)

            # Score (avec analyse whale)
            score, base_score, momentum_bonus, whale_analysis = calculate_final_score(pool_data, momentum, multi_pool_data)

            # NOUVEAU: Rejeter immÃ©diatement si WHALE DUMP dÃ©tectÃ©
            if whale_analysis['pattern'] == 'WHALE_SELLING':
                log(f"   ğŸš¨ {pool_data['name']}: WHALE DUMP dÃ©tectÃ© - REJETÃ‰")
                tokens_rejected += 1
                continue

            # FILTRE SCORE PAR RÃ‰SEAU (maintenant que le score est calculÃ©!)
            network = pool_data.get('network', '').lower()
            min_score_required = NETWORK_SCORE_FILTERS.get(network, {}).get('min_score', 85)

            # Token watchlist: bypass filtre score
            if not check_watchlist_token(pool_data) and score < min_score_required:
                log(f"   â­ï¸  {pool_data['name']}: [V3 REJECT] Score insuffisant: {score} < {min_score_required} ({network.upper()})")
                tokens_rejected += 1
                continue

            # Validation
            is_valid, reason = is_valid_opportunity(pool_data, score)

            if is_valid:
                # DÃ©tecter signaux
                signals = detect_signals(pool_data, momentum, multi_pool_data)

                # Ajouter signaux whale aux signaux existants
                if whale_analysis['signals']:
                    signals.extend(whale_analysis['signals'])

                opportunities.append({
                    "pool_data": pool_data,
                    "score": score,
                    "base_score": base_score,
                    "momentum_bonus": momentum_bonus,
                    "whale_analysis": whale_analysis,  # NOUVEAU
                    "momentum": momentum,
                    "multi_pool_data": multi_pool_data,
                    "signals": signals,
                    "resistance_data": resistance_data,
                })

                log(f"   âœ… OpportunitÃ©: {pool_data['name']} (Score: {score})")
            else:
                log(f"   â­ï¸  {pool_data['name']}: {reason}")

    # Trier par score
    opportunities.sort(key=lambda x: x["score"], reverse=True)

    log(f"\nğŸ“Š TOTAL: {len(opportunities)} opportunitÃ©s dÃ©tectÃ©es")

    # Envoyer alertes
    alerts_sent = 0
    # tokens_rejected dÃ©jÃ  initialisÃ© ligne 2078

    for opp in opportunities:
        base_token = opp["pool_data"]["base_token_name"]
        pool_addr = opp["pool_data"]["pool_address"]
        alert_key = f"{base_token}_{pool_addr}"

        # ==========================================
        # VÃ‰RIFICATION DE SÃ‰CURITÃ‰
        # ==========================================
        # Utiliser pool_address comme token_address (c'est l'adresse du pool/token)
        token_address = opp["pool_data"]["pool_address"]
        network = opp["pool_data"]["network"]

        log(f"\nğŸ”’ VÃ©rification sÃ©curitÃ©: {opp['pool_data']['name']}")

        security_result = security_checker.check_token_security(token_address, network)

        # VÃ©rifier si le token passe les critÃ¨res de sÃ©curitÃ©
        should_send, reason = security_checker.should_send_alert(security_result, min_security_score=50)

        if not should_send:
            log(f"â›” Token rejetÃ©: {reason}")
            log(f"   Score sÃ©curitÃ©: {security_result['security_score']}/100")
            log(f"   Niveau risque: {security_result['risk_level']}")
            tokens_rejected += 1
            continue

        log(f"âœ… SÃ©curitÃ© validÃ©e (Score: {security_result['security_score']}/100)")

        # ==========================================
        # ENVOI DE L'ALERTE (aprÃ¨s validation sÃ©curitÃ©)
        # ==========================================

        # VÃ©rifier si c'est la premiÃ¨re alerte pour ce token
        is_first_alert = not alert_tracker.token_already_alerted(token_address)

        # GÃ©nÃ©rer le message d'alerte (pour rÃ©cupÃ©rer regle5_data)
        alert_msg, regle5_data = generer_alerte_complete(
            opp["pool_data"],
            opp["score"],
            opp["base_score"],
            opp["momentum_bonus"],
            opp["momentum"],
            opp["multi_pool_data"],
            opp["signals"],
            opp["resistance_data"],
            opp.get("whale_analysis"),  # NOUVEAU: Passer analyse whale
            is_first_alert,
            alert_tracker  # Passer le tracker pour l'analyse TP
        )

        # NOUVEAU: VÃ©rifier si on doit envoyer l'alerte (FIX BUG #1 - SPAM)
        price = opp["pool_data"].get("price_usd", 0)
        should_send, send_reason = should_send_alert(token_address, price, alert_tracker, regle5_data)

        if not should_send:
            log(f"â¸ï¸ Alerte bloquÃ©e (anti-spam): {opp['pool_data']['name']}")
            log(f"   Raison: {send_reason}")
            continue

        # Legacy cooldown check (pour compatibilitÃ©)
        if check_cooldown(alert_key):
            # Ajouter les infos de sÃ©curitÃ© Ã  l'alerte
            security_info = security_checker.format_security_warning(security_result)
            alert_msg = alert_msg + "\n" + security_info

            if send_telegram(alert_msg):
                log(f"âœ… Alerte envoyÃ©e: {opp['pool_data']['name']} (Score: {opp['score']})")

                # ==========================================
                # SAUVEGARDE EN BASE DE DONNÃ‰ES + TRACKING AUTO
                # ==========================================
                try:
                    # PrÃ©parer les donnÃ©es pour la DB
                    price = opp["pool_data"].get("price_usd", 0)
                    entry_price = price
                    stop_loss_price = price * 0.90  # -10%
                    tp1_price = price * 1.05  # +5%
                    tp2_price = price * 1.10  # +10%
                    tp3_price = price * 1.15  # +15%

                    alert_data = {
                        'token_name': opp["pool_data"]["name"],
                        'token_address': token_address,
                        'network': network,
                        'price_at_alert': price,
                        'score': opp["score"],
                        'base_score': opp["base_score"],
                        'momentum_bonus': opp["momentum_bonus"],
                        'confidence_score': security_result['security_score'],
                        'volume_24h': opp["pool_data"].get("volume_24h", 0),
                        'volume_6h': opp["pool_data"].get("volume_6h", 0),
                        'volume_1h': opp["pool_data"].get("volume_1h", 0),
                        'liquidity': opp["pool_data"].get("liquidity", 0),
                        'buys_24h': opp["pool_data"].get("buys_24h", 0),
                        'sells_24h': opp["pool_data"].get("sells_24h", 0),
                        'buy_ratio': opp["pool_data"].get("buy_ratio", 0),
                        'total_txns': opp["pool_data"].get("total_txns", 0),
                        'age_hours': opp["pool_data"].get("age_hours", 0),
                        'volume_acceleration_1h_vs_6h': opp["pool_data"].get("volume_acceleration_1h_vs_6h", 0),
                        'volume_acceleration_6h_vs_24h': opp["pool_data"].get("volume_acceleration_6h_vs_24h", 0),
                        'entry_price': entry_price,
                        'stop_loss_price': stop_loss_price,
                        'stop_loss_percent': -10,
                        'tp1_price': tp1_price,
                        'tp1_percent': 5,
                        'tp2_price': tp2_price,
                        'tp2_percent': 10,
                        'tp3_price': tp3_price,
                        'tp3_percent': 15,
                        'alert_message': alert_msg,
                        # RÃˆGLE 5: DonnÃ©es de vÃ©locitÃ© du pump
                        'velocite_pump': regle5_data['velocite_pump'],
                        'type_pump': regle5_data['type_pump'],
                        'decision_tp_tracking': regle5_data['decision_tp_tracking'],
                        'temps_depuis_alerte_precedente': regle5_data['temps_depuis_alerte_precedente'],
                        'is_alerte_suivante': regle5_data['is_alerte_suivante']
                    }

                    alert_id = alert_tracker.save_alert(alert_data)
                    if alert_id > 0:
                        log(f"   ğŸ’¾ SauvegardÃ© en DB (ID: {alert_id}) - Tracking auto dÃ©marrÃ©")
                    else:
                        log(f"   âš ï¸ Ã‰chec sauvegarde DB (token dÃ©jÃ  existant?)")

                except Exception as e:
                    log(f"   âš ï¸ Erreur sauvegarde DB: {e}")

                alerts_sent += 1
            else:
                log(f"âŒ Ã‰chec alerte: {opp['pool_data']['name']}")

            if alerts_sent >= MAX_ALERTS_PER_SCAN:
                log(f"âš ï¸ Limite {MAX_ALERTS_PER_SCAN} alertes atteinte")
                break

            time.sleep(1)
        else:
            # Cooldown actif - alerte bloquÃ©e (ne devrait jamais arriver avec COOLDOWN_SECONDS = 0)
            log(f"â° Alerte bloquÃ©e (cooldown actif): {opp['pool_data']['name']}")

    # ==========================================
    # TRACKING ACTIF DES ALERTES (BACKTESTING)
    # ==========================================
    if ENABLE_ACTIVE_TRACKING and alert_tracker is not None:
        log(f"\nğŸ“¡ TRACKING ACTIF: VÃ©rification des pools alertÃ©s...")

        active_alerts = alert_tracker.get_active_alerts(max_age_hours=ACTIVE_TRACKING_MAX_AGE_HOURS)
        log(f"   ğŸ” {len(active_alerts)} alertes actives Ã  tracker (< {ACTIVE_TRACKING_MAX_AGE_HOURS}h)")

        updates_sent = 0
        for alert in active_alerts:
            try:
                alert_id = alert['id']
                token_name = alert['token_name']
                pool_address = alert['token_address']
                network = alert['network']
                created_at_str = alert['created_at']

                # VÃ©rifier cooldown (Ã©viter spam)
                from datetime import datetime
                created_at = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))
                now = datetime.now(created_at.tzinfo) if created_at.tzinfo else datetime.now()
                minutes_elapsed = (now - created_at).total_seconds() / 60

                # VÃ©rifier si derniÃ¨re mise Ã  jour Ã©tait il y a moins de COOLDOWN minutes
                # Pour simplifier, on considÃ¨re que si l'alerte a moins de COOLDOWN minutes, on skip
                if minutes_elapsed < ACTIVE_TRACKING_UPDATE_COOLDOWN_MINUTES:
                    continue  # Trop rÃ©cent, skip

                # RÃ©cupÃ©rer donnÃ©es actuelles du pool
                pool_data = get_pool_by_address(network, pool_address)

                if not pool_data or not isinstance(pool_data, dict):
                    # Pool plus disponible (delisted, erreur API, etc.)
                    log(f"   âš ï¸ Pool data invalide pour {token_name}: {type(pool_data)}")
                    continue

                current_price = pool_data.get('price_usd', 0)

                if current_price <= 0:
                    continue

                # Mettre Ã  jour le prix MAX en temps rÃ©el
                alert_tracker.update_price_max_realtime(alert_id, current_price)

                # VÃ©rifier si on doit envoyer une mise Ã  jour Telegram
                should_send, reason = should_send_alert(pool_address, current_price, alert_tracker, None)

                if should_send:
                    log(f"   ğŸ”„ Mise Ã  jour: {token_name} - {reason}")

                    # RÃ©cupÃ©rer momentum et multi-pool (optionnel pour mises Ã  jour)
                    momentum = get_price_momentum_from_api(pool_data)
                    multi_pool_data = {}  # Optionnel pour updates

                    # Calculer score et whale analysis
                    score, base_score, momentum_bonus, whale_analysis = calculate_final_score(pool_data, momentum, multi_pool_data)

                    # GÃ©nÃ©rer message d'alerte (is_first_alert = False)
                    try:
                        alert_msg, regle5_data = generer_alerte_complete(
                            pool_data, score, base_score, momentum_bonus, momentum,
                            multi_pool_data, [], None, whale_analysis,
                            is_first_alert=False,  # C'est une mise Ã  jour
                            tracker=alert_tracker
                        )
                    except Exception as gen_error:
                        log(f"   âŒ Erreur gÃ©nÃ©ration alerte pour {token_name}: {gen_error}")
                        import traceback
                        log(f"   Traceback: {traceback.format_exc()}")
                        continue  # Skip cette alerte

                    # Envoyer via Telegram
                    success = send_telegram(alert_msg)

                    if success:
                        updates_sent += 1
                        log(f"   âœ… Mise Ã  jour envoyÃ©e pour {token_name}")

                        # Limiter le nombre de mises Ã  jour par scan
                        if updates_sent >= 5:  # Max 5 mises Ã  jour par scan
                            log(f"   âš ï¸ Limite 5 mises Ã  jour atteinte")
                            break
                    else:
                        log(f"   âŒ Ã‰chec envoi mise Ã  jour: {token_name}")

                    time.sleep(1)  # Pause entre mises Ã  jour

            except Exception as e:
                log(f"   âŒ Erreur tracking {alert.get('token_name', 'unknown')}: {e}")

        log(f"   ğŸ“Š Tracking terminÃ©: {updates_sent} mises Ã  jour envoyÃ©es")

    # ==========================================
    # STATISTIQUES SOURCES DE LIQUIDITÃ‰
    # ==========================================
    log(f"\nğŸ“Š STATISTIQUES SOURCES DE LIQUIDITÃ‰:")
    log(f"   Total pools analysÃ©s: {sum(liquidity_stats.values())}")

    total_pools = sum(liquidity_stats.values())
    if total_pools > 0:
        real_reserve = liquidity_stats.get('reserve_in_usd', 0)
        fdv_estimate = liquidity_stats.get('fdv_usd(10%)', 0)
        mcap_estimate = liquidity_stats.get('market_cap(15%)', 0)
        vol_estimate = liquidity_stats.get('volume_24h(x5)', 0)
        none_liq = liquidity_stats.get('none', 0)

        # Calculer pourcentages
        real_pct = (real_reserve / total_pools) * 100
        fdv_pct = (fdv_estimate / total_pools) * 100
        mcap_pct = (mcap_estimate / total_pools) * 100
        vol_pct = (vol_estimate / total_pools) * 100
        none_pct = (none_liq / total_pools) * 100

        log(f"   âœ… reserve_in_usd (REAL):      {real_reserve:4d} pools ({real_pct:5.1f}%)")

        if fdv_estimate + mcap_estimate + vol_estimate + none_liq > 0:
            log(f"   âš ï¸  ESTIMATIONS (FALLBACK):")
            if fdv_estimate > 0:
                log(f"      â€¢ fdv_usd (10%):           {fdv_estimate:4d} pools ({fdv_pct:5.1f}%)")
            if mcap_estimate > 0:
                log(f"      â€¢ market_cap (15%):        {mcap_estimate:4d} pools ({mcap_pct:5.1f}%)")
            if vol_estimate > 0:
                log(f"      â€¢ volume_24h (x5):         {vol_estimate:4d} pools ({vol_pct:5.1f}%)")
            if none_liq > 0:
                log(f"      â€¢ none (LIQ=0):            {none_liq:4d} pools ({none_pct:5.1f}%)")

        # RÃ©sumÃ© qualitÃ© des donnÃ©es
        if real_pct >= 90:
            log(f"   ğŸ¯ EXCELLENT: {real_pct:.1f}% de donnÃ©es rÃ©elles")
        elif real_pct >= 70:
            log(f"   âœ… BON: {real_pct:.1f}% de donnÃ©es rÃ©elles")
        elif real_pct >= 50:
            log(f"   âš ï¸  MOYEN: Seulement {real_pct:.1f}% de donnÃ©es rÃ©elles")
        else:
            log(f"   ğŸš¨ CRITIQUE: Seulement {real_pct:.1f}% de donnÃ©es rÃ©elles!")

    log(f"\nâœ… Scan terminÃ©: {alerts_sent} alertes envoyÃ©es, {tokens_rejected} tokens rejetÃ©s (sÃ©curitÃ©)")
    log("=" * 80)

# ============================================
# MAIN
# ============================================
def main():
    """Boucle principale."""
    global security_checker, alert_tracker

    log("=" * 80)
    log("ğŸš€ GeckoTerminal Scanner V3.2.5 - Liquidity Quality Check")
    log("=" * 80)
    log("âœ… CONFIGURATION DASHBOARD ACTIVE")
    log("   Objectif: 5 alertes/jour | Score 91.4 | WR 45-58%")
    log("ğŸ” NOUVEAU: Tracking permanent des sources de liquiditÃ©")
    log("   VÃ©rifie si reserve_in_usd (REAL) vs fallback estimations")
    log("=" * 80)
    log(f"ğŸ“¡ RÃ©seaux surveillÃ©s: {', '.join([n.upper() for n in NETWORKS])}")
    log(f"ğŸ“‹ Scores min par rÃ©seau:")
    log(f"   â€¢ ETH: 78+ | BASE: 82+ | BSC: 80+ | SOLANA: 72+")
    log(f"   â€¢ POLYGON: 75+ | AVALANCHE: 80+")
    log(f"â° Age max: {MAX_TOKEN_AGE_HOURS}h")
    log(f"ğŸ”„ Scan toutes les 5 minutes (1 page/rÃ©seau)")
    log(f"ğŸ¯ Max {MAX_ALERTS_PER_SCAN} alertes par scan")
    log("=" * 80)

    # Initialiser le systÃ¨me de sÃ©curitÃ© et tracking
    log("\nğŸ”’ Initialisation du systÃ¨me de sÃ©curitÃ©...")
    security_checker = SecurityChecker()

    # Chemin DB : volume persistant Railway (/data) ou local
    db_path = os.getenv("DB_PATH", "/data/alerts_history.db")
    alert_tracker = AlertTracker(db_path=db_path)
    log(f"ğŸ’¾ Base de donnÃ©es: {db_path}")

    log("âœ… SystÃ¨me de sÃ©curitÃ© activÃ©")

    while True:
        try:
            scan_geckoterminal()

            log("\nğŸ’¤ Pause 5 min avant prochain scan...\n")
            time.sleep(300)

        except KeyboardInterrupt:
            log("\nâ¹ï¸  ArrÃªt du scanner")
            break

        except Exception as e:
            log(f"âŒ Erreur: {e}")
            import traceback
            traceback.print_exc()
            log("â³ Pause 60s avant retry...")
            time.sleep(60)

    # Fermer proprement les connexions
    if alert_tracker:
        log("ğŸ”’ Fermeture de la base de donnÃ©es...")
        alert_tracker.close()
        log("âœ… Base de donnÃ©es fermÃ©e")

if __name__ == "__main__":
    main()

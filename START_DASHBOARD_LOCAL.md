# D√©marrer le Dashboard en Local avec Donn√©es R√©elles

## üéØ Objectif

Faire tourner le scanner V3 localement pour collecter de vraies alertes, puis visualiser dans le dashboard.

---

## √âtape 1: Pr√©parer le Scanner

Le scanner V3 est d√©j√† configur√© pour √©crire dans `alerts_live.json` automatiquement.

**V√©rifications**:
1. ‚úÖ `json_alert_writer.py` existe
2. ‚úÖ Scanner V3 importe `JSONAlertWriter` (ligne 37)
3. ‚úÖ Scanner initialise `json_writer` dans `main()` (ligne 3172)
4. ‚úÖ Scanner sauvegarde alertes dans JSON (ligne 3028)

---

## √âtape 2: Lancer le Scanner V3

### Option A: Mode Normal (Scan Continu)

**Terminal 1** - Scanner:
```bash
cd c:\Users\ludo_\Documents\projets\owner\bot-market
python geckoterminal_scanner_v3.py
```

Le scanner va:
1. Scanner GeckoTerminal toutes les 5 minutes
2. D√©tecter des opportunit√©s
3. Filtrer avec config ULTRA_RENTABLE (tr√®s strict)
4. Sauvegarder les alertes valides dans `alerts_live.json`
5. Envoyer notification Telegram

**Temps d'attente**: ~1-2h pour avoir les premi√®res alertes (config stricte = 2.7/jour)

### Option B: Mode Test Rapide (Donn√©es Historiques)

Si tu veux tester le dashboard **imm√©diatement**, on peut importer les alertes depuis la base Railway:

**Cr√©er un script d'import**:
```python
# import_railway_alerts.py
import json
import sqlite3
from datetime import datetime

# Connexion √† la DB Railway export√©e
conn = sqlite3.connect('alerts_railway_export.db')
cursor = conn.execute("""
    SELECT
        pool_address, network, token_name, token_symbol,
        score, tier, price, liquidity, volume_24h,
        age_hours, created_at
    FROM alerts
    ORDER BY created_at DESC
    LIMIT 100
""")

alerts = []
for row in cursor.fetchall():
    alert_data = json.loads(row[11]) if len(row) > 11 else {}

    alerts.append({
        'pool_address': row[0],
        'network': row[1],
        'token_name': row[2],
        'token_symbol': row[3],
        'score': row[4],
        'tier': row[5],
        'price': row[6],
        'liquidity': row[7],
        'volume_24h': row[8],
        'age_hours': row[9],
        'velocite_pump': alert_data.get('velocite_pump', 0),
        'type_pump': alert_data.get('type_pump', ''),
        'created_at': row[10]
    })

with open('alerts_live.json', 'w', encoding='utf-8') as f:
    json.dump(alerts, f, indent=2, ensure_ascii=False)

print(f"‚úÖ {len(alerts)} alertes import√©es dans alerts_live.json")
```

Mais **MIEUX**: On peut utiliser le fichier d'export JSON que tu as d√©j√†!

---

## √âtape 3: Convertir les Alertes Railway Existantes

Tu as d√©j√† un export des alertes Railway. Convertissons-le au format du dashboard:

**Script de conversion**:

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analyse compl√®te de TOUS les tokens d√©tect√©s
Trouve les patterns des meilleurs scores par blockchain
"""
import sqlite3
import os
import sys
from collections import defaultdict

# Fix Windows console encoding
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# Find the database
DB_PATH = os.getenv("DB_PATH")
if not DB_PATH:
    if os.path.exists("alerts_tracker.db"):
        DB_PATH = "alerts_tracker.db"
    elif os.path.exists("alerts_history.db"):
        DB_PATH = "alerts_history.db"
    else:
        print("‚ùå ERROR: Database not found!")
        exit(1)

print(f"üìä Analyse des tokens d√©tect√©s\n")
print(f"Database: {DB_PATH}\n")

def get_top_tokens(conn, network=None, limit=15):
    """R√©cup√®re les top tokens par score pour un r√©seau"""

    query = """
        SELECT
            token_name,
            token_address,
            network,
            score,
            base_score,
            momentum_bonus,
            confidence_score,
            liquidity,
            volume_24h,
            volume_6h,
            volume_1h,
            age_hours,
            buy_ratio,
            volume_acceleration_1h_vs_6h,
            entry_price,
            tp1_percent,
            tp2_percent,
            tp3_percent,
            created_at
        FROM alerts
        {}
        ORDER BY score DESC, liquidity DESC
        LIMIT ?
    """.format("WHERE network = ?" if network else "")

    params = [network, limit] if network else [limit]
    cursor = conn.execute(query, params)

    return cursor.fetchall()

def analyze_patterns(tokens, network_name):
    """Analyse les patterns communs des top scorers"""

    print(f"\n{'='*100}")
    print(f"üéØ ANALYSE: {network_name.upper()}")
    print(f"{'='*100}\n")

    if not tokens:
        print("‚ùå Aucun token trouv√©\n")
        return None

    print(f"üìä TOP {len(tokens)} TOKENS (par score):\n")
    print(f"{'#':<3} {'Token':<25} {'Score':<7} {'Tier':<12} {'Liq':<12} {'Vol 24h':<12} {'Age':<10} {'Accel':<8}")
    print("‚îÄ" * 100)

    patterns = {
        'score_distribution': defaultdict(int),
        'liquidity_range': [],
        'volume_range': [],
        'age_distribution': [],
        'momentum_distribution': [],
        'acceleration_distribution': [],
        'buy_ratio_distribution': [],
        'tp_targets': {'tp1': [], 'tp2': [], 'tp3': []}
    }

    for i, token in enumerate(tokens, 1):
        # Determine tier
        score = token['score']
        if score >= 95:
            tier = 'ULTRA_HIGH'
        elif score >= 85:
            tier = 'HIGH'
        elif score >= 75:
            tier = 'MEDIUM'
        else:
            tier = 'LOW'

        patterns['score_distribution'][tier] += 1

        token_name = token['token_name'].split('/')[0] if token['token_name'] else 'Unknown'
        liq = token['liquidity'] or 0
        vol = token['volume_24h'] or 0
        age_min = (token['age_hours'] or 0) * 60
        accel = token['volume_acceleration_1h_vs_6h'] or 0

        # Print token
        print(f"{i:<3} {token_name[:24]:<25} "
              f"{score:<7} "
              f"{tier:<12} "
              f"${liq/1000:>7.0f}K   "
              f"${vol/1000:>7.0f}K   "
              f"{age_min:>6.0f}min "
              f"{accel:>6.1f}x")

        # Collect patterns
        patterns['liquidity_range'].append(liq)
        patterns['volume_range'].append(vol)
        patterns['age_distribution'].append(age_min)

        if token['momentum_bonus']:
            patterns['momentum_distribution'].append(token['momentum_bonus'])

        if accel:
            patterns['acceleration_distribution'].append(accel)

        if token['buy_ratio']:
            patterns['buy_ratio_distribution'].append(token['buy_ratio'])

        if token['tp1_percent']:
            patterns['tp_targets']['tp1'].append(token['tp1_percent'])
        if token['tp2_percent']:
            patterns['tp_targets']['tp2'].append(token['tp2_percent'])
        if token['tp3_percent']:
            patterns['tp_targets']['tp3'].append(token['tp3_percent'])

    print("\n" + "‚îÄ" * 100)

    # Statistical Analysis
    print(f"\nüîç PATTERNS IDENTIFI√âS:\n")

    # Score distribution
    print(f"  üìä DISTRIBUTION DES TIERS:")
    total = len(tokens)
    for tier in ['ULTRA_HIGH', 'HIGH', 'MEDIUM', 'LOW']:
        count = patterns['score_distribution'][tier]
        pct = (count/total)*100 if total > 0 else 0
        print(f"     ‚Ä¢ {tier:12}: {count}/{total} ({pct:.0f}%)")

    # Liquidity
    if patterns['liquidity_range']:
        liq_sorted = sorted([l for l in patterns['liquidity_range'] if l > 0])
        if liq_sorted:
            print(f"\n  üí∞ LIQUIDIT√â:")
            print(f"     ‚Ä¢ Moyenne: ${sum(liq_sorted)/len(liq_sorted)/1000:.0f}K")
            print(f"     ‚Ä¢ M√©diane: ${liq_sorted[len(liq_sorted)//2]/1000:.0f}K")
            print(f"     ‚Ä¢ Min: ${min(liq_sorted)/1000:.0f}K")
            print(f"     ‚Ä¢ Max: ${max(liq_sorted)/1000:.0f}K")
            # Sweet spot analysis
            over_50k = sum(1 for l in liq_sorted if l >= 50000)
            over_100k = sum(1 for l in liq_sorted if l >= 100000)
            print(f"     ‚Ä¢ ‚â•$50K: {over_50k}/{len(liq_sorted)} ({over_50k/len(liq_sorted)*100:.0f}%)")
            print(f"     ‚Ä¢ ‚â•$100K: {over_100k}/{len(liq_sorted)} ({over_100k/len(liq_sorted)*100:.0f}%)")

    # Volume
    if patterns['volume_range']:
        vol_sorted = sorted([v for v in patterns['volume_range'] if v > 0])
        if vol_sorted:
            print(f"\n  üìà VOLUME 24H:")
            print(f"     ‚Ä¢ Moyenne: ${sum(vol_sorted)/len(vol_sorted)/1000:.0f}K")
            print(f"     ‚Ä¢ M√©diane: ${vol_sorted[len(vol_sorted)//2]/1000:.0f}K")
            over_100k = sum(1 for v in vol_sorted if v >= 100000)
            print(f"     ‚Ä¢ ‚â•$100K: {over_100k}/{len(vol_sorted)} ({over_100k/len(vol_sorted)*100:.0f}%)")

    # Age
    if patterns['age_distribution']:
        age_sorted = sorted([a for a in patterns['age_distribution'] if a >= 0])
        print(f"\n  ‚è∞ √ÇGE √Ä LA D√âTECTION:")
        print(f"     ‚Ä¢ Moyenne: {sum(age_sorted)/len(age_sorted):.0f} minutes")
        print(f"     ‚Ä¢ M√©diane: {age_sorted[len(age_sorted)//2]:.0f} minutes")
        under_5 = sum(1 for a in age_sorted if a < 5)
        under_30 = sum(1 for a in age_sorted if a < 30)
        under_60 = sum(1 for a in age_sorted if a < 60)
        print(f"     ‚Ä¢ <5min:  {under_5}/{len(age_sorted)} ({under_5/len(age_sorted)*100:.0f}%)")
        print(f"     ‚Ä¢ <30min: {under_30}/{len(age_sorted)} ({under_30/len(age_sorted)*100:.0f}%)")
        print(f"     ‚Ä¢ <1h:    {under_60}/{len(age_sorted)} ({under_60/len(age_sorted)*100:.0f}%)")

    # Momentum
    if patterns['momentum_distribution']:
        mom_sorted = sorted(patterns['momentum_distribution'])
        print(f"\n  üöÄ MOMENTUM BONUS:")
        print(f"     ‚Ä¢ Moyenne: +{sum(mom_sorted)/len(mom_sorted):.1f} points")
        print(f"     ‚Ä¢ Max: +{max(mom_sorted):.0f} points")

    # Acceleration
    if patterns['acceleration_distribution']:
        accel_sorted = sorted([a for a in patterns['acceleration_distribution'] if a > 0])
        if accel_sorted:
            print(f"\n  ‚ö° ACC√âL√âRATION VOLUME (1h vs 6h):")
            print(f"     ‚Ä¢ Moyenne: {sum(accel_sorted)/len(accel_sorted):.1f}x")
            print(f"     ‚Ä¢ M√©diane: {accel_sorted[len(accel_sorted)//2]:.1f}x")
            over_2x = sum(1 for a in accel_sorted if a >= 2)
            over_5x = sum(1 for a in accel_sorted if a >= 5)
            print(f"     ‚Ä¢ ‚â•2x: {over_2x}/{len(accel_sorted)} ({over_2x/len(accel_sorted)*100:.0f}%)")
            print(f"     ‚Ä¢ ‚â•5x: {over_5x}/{len(accel_sorted)} ({over_5x/len(accel_sorted)*100:.0f}%)")

    # Buy Ratio
    if patterns['buy_ratio_distribution']:
        buy_sorted = sorted(patterns['buy_ratio_distribution'])
        print(f"\n  ‚úÖ BUY RATIO:")
        print(f"     ‚Ä¢ Moyenne: {sum(buy_sorted)/len(buy_sorted):.1%}")
        print(f"     ‚Ä¢ M√©diane: {buy_sorted[len(buy_sorted)//2]:.1%}")

    # TP Targets
    print(f"\n  üéØ TARGETS RECOMMAND√âS:")
    if patterns['tp_targets']['tp1']:
        avg_tp1 = sum(patterns['tp_targets']['tp1'])/len(patterns['tp_targets']['tp1'])
        print(f"     ‚Ä¢ TP1: +{avg_tp1:.0f}%")
    if patterns['tp_targets']['tp2']:
        avg_tp2 = sum(patterns['tp_targets']['tp2'])/len(patterns['tp_targets']['tp2'])
        print(f"     ‚Ä¢ TP2: +{avg_tp2:.0f}%")
    if patterns['tp_targets']['tp3']:
        avg_tp3 = sum(patterns['tp_targets']['tp3'])/len(patterns['tp_targets']['tp3'])
        print(f"     ‚Ä¢ TP3: +{avg_tp3:.0f}%")

    return patterns

def generate_trading_rules(all_patterns):
    """G√©n√®re des r√®gles de trading bas√©es sur les patterns r√©els"""

    print(f"\n\n{'='*100}")
    print("üéØ STRAT√âGIE DE TRADING OPTIMALE (Bas√©e sur vos donn√©es r√©elles)")
    print(f"{'='*100}\n")

    # Aggregate stats
    all_liq = []
    all_vol = []
    all_ages = []
    all_scores = []
    tier_dist = defaultdict(int)

    for network, patterns in all_patterns.items():
        if patterns:
            all_liq.extend(patterns['liquidity_range'])
            all_vol.extend(patterns['volume_range'])
            all_ages.extend(patterns['age_distribution'])
            for tier, count in patterns['score_distribution'].items():
                tier_dist[tier] += count

    # Filter out zeros
    all_liq = [l for l in all_liq if l > 0]
    all_vol = [v for v in all_vol if v > 0]
    all_ages = [a for a in all_ages if a >= 0]

    print("‚úÖ R√àGLES D'ENTRY (Niveau de confiance par blockchain):\n")

    print("  üìã CHECKLIST PR√â-TRADE:\n")

    if all_liq:
        median_liq = sorted(all_liq)[len(all_liq)//2]
        p75_liq = sorted(all_liq)[int(len(all_liq)*0.75)]
        print(f"     1. LIQUIDIT√â:")
        print(f"        ‚Ä¢ Minimum absolu: >${median_liq/1000:.0f}K (m√©diane)")
        print(f"        ‚Ä¢ Recommand√©: >${p75_liq/1000:.0f}K (top 25%)")

    if all_vol:
        median_vol = sorted(all_vol)[len(all_vol)//2]
        print(f"\n     2. VOLUME 24H:")
        print(f"        ‚Ä¢ Minimum: >${median_vol/1000:.0f}K (m√©diane)")

    total_tokens = sum(tier_dist.values())
    ultra_high_pct = (tier_dist['ULTRA_HIGH']/total_tokens)*100 if total_tokens > 0 else 0
    high_pct = (tier_dist['HIGH']/total_tokens)*100 if total_tokens > 0 else 0

    print(f"\n     3. SCORE:")
    print(f"        ‚Ä¢ ULTRA_HIGH (‚â•95): {ultra_high_pct:.0f}% des d√©tections ‚≠ê‚≠ê‚≠ê")
    print(f"        ‚Ä¢ HIGH (‚â•85): {high_pct:.0f}% des d√©tections ‚≠ê‚≠ê")
    print(f"        ‚Üí Privil√©gier uniquement ULTRA_HIGH & HIGH")

    if all_ages:
        median_age = sorted(all_ages)[len(all_ages)//2]
        under_30 = sum(1 for a in all_ages if a < 30)
        fresh_pct = (under_30/len(all_ages))*100
        print(f"\n     4. FRESHNESS (√ÇGE):")
        print(f"        ‚Ä¢ {fresh_pct:.0f}% des tokens d√©tect√©s √† <30min")
        print(f"        ‚Ä¢ M√©diane: {median_age:.0f} minutes")
        print(f"        ‚Üí Agir rapidement sur les <30min signals")

    print(f"\n\n  üí° STRAT√âGIES PAR BLOCKCHAIN:\n")

    for network, patterns in all_patterns.items():
        if not patterns:
            continue

        liq_data = [l for l in patterns['liquidity_range'] if l > 0]
        age_data = [a for a in patterns['age_distribution'] if a >= 0]

        if liq_data and age_data:
            med_liq = sorted(liq_data)[len(liq_data)//2]
            med_age = sorted(age_data)[len(age_data)//2]
            ultra_high = patterns['score_distribution']['ULTRA_HIGH']
            total = sum(patterns['score_distribution'].values())
            quality_pct = (ultra_high/total)*100 if total > 0 else 0

            print(f"     {network.upper():10} ‚Üí Liq m√©diane: ${med_liq/1000:>6.0f}K | √Çge m√©dian: {med_age:>4.0f}min | ULTRA_HIGH: {quality_pct:.0f}%")

    print(f"\n\n  üé≤ GESTION DU RISQUE:\n")
    print(f"     ‚Ä¢ Position size max: 3-5% du capital par trade")
    print(f"     ‚Ä¢ Stop loss: -10% strict (non n√©gociable)")
    print(f"     ‚Ä¢ Take profit partiel (50%) √† TP1")
    print(f"     ‚Ä¢ Trail stop sur le reste apr√®s TP1")
    print(f"     ‚Ä¢ Maximum 3-5 positions ouvertes simultan√©ment")

    print(f"\n  ‚ö° SIGNAUX D'ACTION:\n")
    print(f"     üü¢ ENTRY si:")
    print(f"        - Score ‚â•90 (ULTRA_HIGH ou HIGH top)")
    print(f"        - Liquidity > m√©diane r√©seau")
    print(f"        - Age <30min (privil√©gier <5min)")
    print(f"        - Volume croissant (si accel >2x = bonus)")
    print(f"\n     üî¥ EXIT imm√©diat si:")
    print(f"        - Liquidity baisse de >20%")
    print(f"        - Volume s'effondre")
    print(f"        - Stop loss touch√© (-10%)")
    print(f"\n     üü° EXIT partiel si:")
    print(f"        - TP1 atteint (+20-30%)")
    print(f"        - 6h √©coul√©es sans nouveau momentum")

    print(f"\n{'‚îÄ'*100}\n")

def main():
    """Main analysis"""

    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row

    # Get total stats
    cursor = conn.execute("SELECT COUNT(*) as total, COUNT(DISTINCT network) as networks FROM alerts")
    stats = cursor.fetchone()
    print(f"üìà Total alertes: {stats['total']}")
    print(f"üåç R√©seaux actifs: {stats['networks']}\n")

    networks = ['eth', 'base', 'bsc', 'solana', 'polygon_pos', 'avax']

    all_patterns = {}

    # Analyze each network
    for network in networks:
        tokens = get_top_tokens(conn, network, limit=15)
        if tokens:
            patterns = analyze_patterns(tokens, network)
            all_patterns[network] = patterns

    # Global analysis
    print(f"\n\n{'='*100}")
    print("üåç ANALYSE GLOBALE (TOP 20 TOUS R√âSEAUX)")
    print(f"{'='*100}")

    all_tokens = get_top_tokens(conn, network=None, limit=20)
    if all_tokens:
        global_patterns = analyze_patterns(all_tokens, "GLOBAL")
        all_patterns['GLOBAL'] = global_patterns

    # Generate trading rules
    generate_trading_rules(all_patterns)

    conn.close()

    print("\n‚úÖ Analyse termin√©e!\n")

if __name__ == "__main__":
    main()
